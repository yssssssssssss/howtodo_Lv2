{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step1 - 对图片进行分类(price/txt/white/scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是旧方法, 速度比较慢\n",
    "\n",
    "\n",
    "# import os\n",
    "# import shutil\n",
    "# from PIL import Image\n",
    "# from paddleocr import PaddleOCR\n",
    "# from tqdm import tqdm\n",
    "# from datetime import datetime\n",
    "# import math\n",
    "# import time\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# z = '猫表_男士春夏下装'\n",
    "\n",
    "\n",
    "\n",
    "# %config IPCompleter.greedy=True\n",
    "\n",
    "# def process_folder(root_folder):\n",
    "#     # 初始化 PaddleOCR\n",
    "#     ocr = PaddleOCR(use_angle_cls=True, lang=\"ch\", show_log=False)\n",
    "\n",
    "#     # 遍历根文件夹下的所有子文件夹\n",
    "#     for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "#         if os.path.basename(dirpath) == 'grounding_output':\n",
    "#             price_folder = os.path.join(dirpath, 'price')\n",
    "#             txt_folder = os.path.join(dirpath, 'txt')\n",
    "#             scene_folder = os.path.join(dirpath, 'scene')\n",
    "#             white_folder = os.path.join(dirpath, 'white')\n",
    "\n",
    "#             # 如果文件夹不存在，则创建\n",
    "#             for folder in [price_folder, txt_folder, scene_folder, white_folder]:\n",
    "#                 if not os.path.exists(folder):\n",
    "#                     os.makedirs(folder)\n",
    "\n",
    "#             '''\n",
    "#             step1 - 筛选价促卖点图\n",
    "#             '''\n",
    "#             print('Step 1: 筛选价促卖点图')\n",
    "\n",
    "#             image_files = [os.path.join(dirpath, filename) for filename in os.listdir(dirpath) if filename.endswith(('.jpg', '.png'))]\n",
    "\n",
    "#             # 使用 tqdm 创建进度条\n",
    "#             with tqdm(total=len(image_files), desc=\"Processing images\") as pbar:\n",
    "#                 # 遍历源文件夹中的所有图片文件\n",
    "#                 for filename in image_files:\n",
    "#                     img_path = os.path.join(dirpath, filename)\n",
    "\n",
    "#                     # 使用 PaddleOCR 进行文字识别\n",
    "#                     result = ocr.ocr(img_path, cls=True)\n",
    "\n",
    "#                     if not result:\n",
    "#                         # 如果识别结果为空,则跳过这张图片,不进行移动操作\n",
    "#                         pbar.write(f\"Image '{filename}' skipped due to empty OCR result.\")\n",
    "#                         pbar.update(1)\n",
    "#                         continue\n",
    "\n",
    "#                     data_list = result[0]\n",
    "\n",
    "#                     # 检查识别结果是否有关键词\n",
    "#                     contains_keyword = False\n",
    "\n",
    "#                     if data_list:\n",
    "#                         # 定义关键词列表\n",
    "#                         keywords = ['满', '减', '折', '到手价', '送', '免息', '活动价', '包邮价', '参考价',\n",
    "#                                     r'.*满.*减.*', r'.*满.*-.*', r'.*满.*赠.*', r'.*满.*送.*', r'.*价.*',\n",
    "#                                     '券', '优惠', '用券', '领券', '券', '送', '低至', '立减', '直降', '免息', \n",
    "#                                     '¥', '夫', '￥', '免费']\n",
    "\n",
    "#                         # 遍历识别结果中的文本\n",
    "#                         for data in data_list:\n",
    "#                             text = data[1][0]  # 获取文本内容\n",
    "#                             # 检查当前文本是否包含关键词\n",
    "#                             if any(keyword in text for keyword in keywords):\n",
    "#                                 contains_keyword = True\n",
    "#                                 break\n",
    "\n",
    "#                     # 根据检查结果移动文件\n",
    "#                     if contains_keyword:\n",
    "#                         try:\n",
    "#                             shutil.move(img_path, price_folder)\n",
    "#                             # pbar.write(f\"Image '{filename}' moved to price_folder.\")\n",
    "#                         except Exception as e:\n",
    "#                             pbar.write(f\"Failed to move image '{filename}': {e}\")\n",
    "#                             continue\n",
    "#                     # else:\n",
    "#                     #     # 如果不包含关键词，移动到其他文件夹\n",
    "#                     #     # 你可以根据需要修改这里的逻辑\n",
    "#                     #     try:\n",
    "#                     #         shutil.move(img_path, txt_folder)\n",
    "#                     #         pbar.write(f\"Image '{filename}' moved to scene_folder.\")\n",
    "#                     #     except Exception as e:\n",
    "#                     #         pbar.write(f\"Failed to move image '{filename}': {e}\")\n",
    "\n",
    "#                     # 重置 contains_keyword 变量\n",
    "#                     contains_keyword = False\n",
    "\n",
    "#                     # 更新进度条\n",
    "#                     pbar.update(1)\n",
    "\n",
    "#             print(\"卖点图 classification completed.\")\n",
    "\n",
    "#             # 获取当前时间\n",
    "#             current_time = datetime.now()\n",
    "\n",
    "#             # 格式化输出当前时间\n",
    "#             print(\"完成时间:\", current_time)\n",
    "\n",
    "#             '''\n",
    "#             step2 - 筛选白底图\n",
    "#             '''\n",
    "\n",
    "#             print('Step 2: 筛选白底图')\n",
    "\n",
    "#             def move_images_with_white_pixels(base_path, white_folder, threshold=0.40):\n",
    "#                 # 获取源文件夹中的图片文件列表\n",
    "#                 image_files = [filename for filename in os.listdir(base_path) if filename.endswith(('.jpg', '.png'))]\n",
    "\n",
    "#                 # 使用 tqdm 创建进度条\n",
    "#                 with tqdm(total=len(image_files), desc=f\"Moving images from {base_path}\") as pbar:\n",
    "#                     # 遍历源文件夹中的所有图片文件\n",
    "#                     for filename in image_files:\n",
    "#                         img_path = os.path.join(base_path, filename)\n",
    "\n",
    "#                         # 打开图片并获取像素信息\n",
    "#                         with Image.open(img_path) as img:\n",
    "#                             # 确认图片是 RGB 模式\n",
    "#                             if img.mode!= 'RGB':\n",
    "#                                 img = img.convert('RGB')\n",
    "#                             # 获取图片的宽度和高度\n",
    "#                             width, height = img.size\n",
    "\n",
    "#                             # 统计白色像素点的数量\n",
    "#                             white_pixels = 0\n",
    "#                             for x in range(width):\n",
    "#                                 for y in range(height):\n",
    "#                                     # 获取像素点的 RGB 值\n",
    "#                                     pixel_value = img.getpixel((x, y))\n",
    "#                                     # 如果是 RGB 图像，解包为三个值，否则为四个值\n",
    "#                                     if len(pixel_value) == 3:\n",
    "#                                         r, g, b = pixel_value\n",
    "#                                     else:  # 处理带有透明度的图像\n",
    "#                                         r, g, b, a = pixel_value\n",
    "#                                     # 如果 RGB 值都大于 230，则认为是白色像素点\n",
    "#                                     if r > 230 and g > 230 and b > 230:\n",
    "#                                         white_pixels += 1\n",
    "\n",
    "#                             # 计算白色像素点占比\n",
    "#                             white_ratio = white_pixels / (width * height)\n",
    "\n",
    "#                             # 如果白色像素点占比超过阈值，则将图片移动到目标文件夹\n",
    "#                             if white_ratio > threshold:\n",
    "#                                 target_path = os.path.join(white_folder, filename)\n",
    "#                                 try:\n",
    "#                                     shutil.move(img_path, white_folder)\n",
    "#                                     # pbar.write(f\"Image '{filename}' moved to white folder.\")\n",
    "#                                 except Exception as e:\n",
    "#                                     pbar.write(f\"Error moving image '{filename}': {e}\")\n",
    "#                                     continue\n",
    "\n",
    "#                         # 更新进度条\n",
    "#                         pbar.update(1)\n",
    "\n",
    "#             # 调用函数，将白色像素点占比超过 30%的图片从源文件夹列表中移动到目标文件夹\n",
    "#             move_images_with_white_pixels(dirpath, white_folder, threshold=0.40)\n",
    "\n",
    "#             # 获取当前时间\n",
    "#             current_time = datetime.now()\n",
    "\n",
    "#             # 格式化输出当前时间\n",
    "#             print(\"完成时间:\", current_time)\n",
    "\n",
    "#             '''\n",
    "#             step3 - 筛选功能卖点图\n",
    "#             '''\n",
    "\n",
    "#             print('Step 3: 筛选功能卖点图')\n",
    "\n",
    "#             image_files = [filename for filename in os.listdir(dirpath) if filename.endswith(('.jpg', '.png'))]\n",
    "#             for filename in image_files:\n",
    "\n",
    "#                 img_path = os.path.join(dirpath, filename)\n",
    "#                 # print(f\"Processing image: {img_path}\")\n",
    "\n",
    "#                 img = Image.open(img_path)\n",
    "#                 width, height = img.size\n",
    "\n",
    "#                 # 读取图片下部分 5/6\n",
    "#                 cropped_img = img.crop((0, height // 6, width, height))\n",
    "\n",
    "#                 # 将 PIL 图像对象转换为 numpy 数组\n",
    "#                 img_np = np.array(cropped_img)\n",
    "\n",
    "#                 # OCR 处理\n",
    "#                 result = ocr.ocr(img_np, cls=True)\n",
    "\n",
    "#                 if result is None:\n",
    "#                     continue\n",
    "\n",
    "#                 rectangles_with_text = result[0]\n",
    "\n",
    "#                 if rectangles_with_text is None:\n",
    "#                     continue\n",
    "\n",
    "#                 line_count = len(rectangles_with_text)\n",
    "\n",
    "#                 # 如果文本行数大于等于 3, 将图片移动到目标文件夹\n",
    "#                 if line_count >= 2:\n",
    "#                     target_path = os.path.join(txt_folder, filename)\n",
    "#                     shutil.move(img_path, txt_folder)\n",
    "#                     # print(f\"'{filename}' moved to txt folder.\")\n",
    "\n",
    "#                 else:\n",
    "#                     # print(f\"'{filename}' remains in source folder.\")\n",
    "#                     continue\n",
    "\n",
    "#             '''\n",
    "#             step4 - 将剩余图片归类到 scene\n",
    "#             '''\n",
    "\n",
    "#             print('Step 4: 归类图片到 scene')\n",
    "\n",
    "#             # 检查目标文件夹是否存在，如果不存在则创建\n",
    "#             if not os.path.exists(scene_folder):\n",
    "#                 os.makedirs(scene_folder)\n",
    "\n",
    "#             # 获取源文件夹中的所有图片文件列表\n",
    "#             image_files = [filename for filename in os.listdir(dirpath) if filename.endswith(('.jpg', '.png'))]\n",
    "\n",
    "#             # 移动图片到 txt_folder\n",
    "#             for filename in image_files:\n",
    "#                 img_path = os.path.join(dirpath, filename)\n",
    "#                 target_path = os.path.join(scene_folder, filename)\n",
    "#                 shutil.move(img_path, scene_folder)\n",
    "#                 # print(f\"Image '{filename}' moved to scene_folder.\")\n",
    "\n",
    "#             print(\"Image moving completed.\")\n",
    "\n",
    "#             # 获取当前时间\n",
    "#             current_time = datetime.now()\n",
    "\n",
    "#             # 格式化输出当前时间\n",
    "#             print(\"完成时间:\", current_time)\n",
    "\n",
    "#             '''\n",
    "#             step5 - 将 white 中有文本的图片移到 txt_folder\n",
    "#             '''\n",
    "\n",
    "#             # 获取源文件夹中的所有图片文件列表\n",
    "#             image_files = [filename for filename in os.listdir(white_folder) if filename.endswith(('.jpg', '.png'))]\n",
    "\n",
    "#             # 使用 tqdm 创建进度条\n",
    "#             with tqdm(total=len(image_files), desc=\"Processing images\") as pbar:\n",
    "\n",
    "#                 # 遍历源文件夹中的所有图片文件\n",
    "#                 for filename in image_files:\n",
    "#                     img_path = os.path.join(white_folder, filename)\n",
    "\n",
    "#                     img = Image.open(img_path)\n",
    "#                     width, height = img.size\n",
    "\n",
    "#                     # 读取图片下部分 3/4\n",
    "#                     cropped_img = img.crop((0, height // 6, width, height))\n",
    "\n",
    "#                     # 将 PIL 图像对象转换为 numpy 数组\n",
    "#                     img_np = np.array(cropped_img)\n",
    "\n",
    "#                     # OCR 处理\n",
    "#                     result = ocr.ocr(img_np, cls=True)\n",
    "\n",
    "#                     if result is None:\n",
    "#                         continue\n",
    "\n",
    "#                     rectangles_with_text = result[0]\n",
    "\n",
    "#                     if rectangles_with_text is None:\n",
    "#                         continue\n",
    "\n",
    "#                     # 统计文本框高度大于 30 像素的行数\n",
    "#                     lines_above_30_count = 0\n",
    "#                     for rectangle in rectangles_with_text:\n",
    "#                         # 计算文本框的高度和宽度\n",
    "#                         points = rectangle[0]\n",
    "#                         x_A, y_A = points[0]\n",
    "\n",
    "#                         # 计算 A 点到 BCD 的距离\n",
    "#                         distances = []\n",
    "#                         for point in points[1:]:\n",
    "#                             x_B, y_B = point\n",
    "#                             distance = math.sqrt((x_B - x_A) ** 2 + (y_B - y_A) ** 2)\n",
    "#                             distances.append(distance)\n",
    "\n",
    "#                         # 获取最短的距离作为文本框的大小\n",
    "#                         text_size = min(distances)\n",
    "\n",
    "#                         # 统计高度大于 x 像素的行数\n",
    "#                         if text_size > 30:\n",
    "#                             lines_above_30_count += 1\n",
    "\n",
    "#                     # 如果大于 30 像素的行数大于等于 2，将图片移动到目标文件夹\n",
    "#                     if lines_above_30_count >= 2:\n",
    "#                         # 如果识别结果不为空且行数小于等于 3，则将图片复制到 txt_folder\n",
    "#                         target_path = os.path.join(txt_folder, filename)\n",
    "#                         shutil.move(img_path, target_path)\n",
    "#                         # pbar.write(f\"Image '{filename}' copied to txt_folder.\")\n",
    "#                     else:\n",
    "#                         # pbar.write(f\"Image '{filename}' remains in source folder.\")\n",
    "#                         continue\n",
    "\n",
    "#                     # 更新进度条\n",
    "#                     pbar.update(1)\n",
    "\n",
    "#             print(\"Image classification completed.\")\n",
    "\n",
    "#             print('okkk')\n",
    "\n",
    "# root_folder = f\"D://code//data//猫表数据//{z}\"\n",
    "# process_folder(root_folder)\n",
    "\n",
    "\n",
    "# # 获取当前时间\n",
    "# current_time = datetime.now()\n",
    "\n",
    "# # 打印当前时间\n",
    "# print(\"当前系统时间是:\", current_time)\n",
    "# print(\"当前系统时间是:\", current_time)\n",
    "# print(\"当前系统时间是:\", current_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4846 images in D://code//data//猫表数据//猫表_男士休闲鞋\\grounding_output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 4846/4846 [30:28<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前系统时间是: 2024-12-04 20:42:07.171037\n",
      "当前系统时间是: 2024-12-04 20:42:07.171037\n",
      "当前系统时间是: 2024-12-04 20:42:07.171037\n"
     ]
    }
   ],
   "source": [
    "# 这是新方法, 先统一识别, 然后再一次性的移动\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from paddleocr import PaddleOCR\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "z = '猫表_男士休闲鞋'\n",
    "\n",
    "\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "\n",
    "def process_folder(root_folder):\n",
    "    # 1. 只初始化一次OCR\n",
    "    ocr = PaddleOCR(use_angle_cls=True, lang=\"ch\", show_log=False)\n",
    "    \n",
    "    # 2. 预先收集所有需要处理的图片\n",
    "    def collect_images(dirpath):\n",
    "        return [f for f in os.listdir(dirpath) if f.endswith(('.jpg', '.png'))]\n",
    "    \n",
    "    # 3. 优化白底图检测\n",
    "    def check_white_background(img, threshold=0.45, sample_rate=5):\n",
    "        \"\"\"使用采样方式检测白底，而不是遍历所有像素\"\"\"\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        width, height = img.size\n",
    "        white_pixels = 0\n",
    "        total_pixels = 0\n",
    "        \n",
    "        # 每隔sample_rate个像素采样一次\n",
    "        for x in range(0, width, sample_rate):\n",
    "            for y in range(0, height, sample_rate):\n",
    "                total_pixels += 1\n",
    "                r, g, b = img.getpixel((x, y))\n",
    "                if r > 230 and g > 230 and b > 230:\n",
    "                    white_pixels += 1\n",
    "                    \n",
    "        return (white_pixels / total_pixels) > threshold\n",
    "    \n",
    "    # 4. 优化OCR文本检测\n",
    "    def process_image_once(img_path):\n",
    "        \"\"\"一次性处理图片，返回所有需要的信息\"\"\"\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            width, height = img.size\n",
    "            \n",
    "            # 检查是否是白底图\n",
    "            is_white = check_white_background(img)\n",
    "            \n",
    "            # OCR处理\n",
    "            result = ocr.ocr(img_path, cls=True)\n",
    "            if not result or not result[0]:\n",
    "                return {'is_white': is_white}\n",
    "                \n",
    "            texts = [line[1][0] for line in result[0]]\n",
    "            text_heights = [abs(line[0][0][1] - line[0][3][1]) for line in result[0]]\n",
    "            \n",
    "            # 检查关键词\n",
    "            keywords = {'满', '减', '折', '到手价', '送', '免息', '活动价', '包邮价', \n",
    "                       '参考价', '券', '优惠', '用券', '领券', '送', '低至', \n",
    "                       '立减', '直降', '免息', '¥', '夫', '￥', '免费'}\n",
    "            has_keywords = any(any(k in text for k in keywords) for text in texts)\n",
    "            \n",
    "            # 检查文本行数\n",
    "            text_lines = sum(1 for h in text_heights if h > 30)\n",
    "            \n",
    "            return {\n",
    "                'is_white': is_white,\n",
    "                'has_keywords': has_keywords,\n",
    "                'text_lines': text_lines,\n",
    "                'texts': texts\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # 5. 批量处理图片\n",
    "    def batch_process_images(dirpath, image_files):\n",
    "        results = {}\n",
    "        with tqdm(total=len(image_files), desc=\"Processing images\") as pbar:\n",
    "            for filename in image_files:\n",
    "                img_path = os.path.join(dirpath, filename)\n",
    "                results[filename] = process_image_once(img_path)\n",
    "                pbar.update(1)\n",
    "        return results\n",
    "    \n",
    "    # 6. 一次性移动文件\n",
    "    def move_files_batch(dirpath, results):\n",
    "        for filename, result in results.items():\n",
    "            if not result:\n",
    "                continue\n",
    "                \n",
    "            source_path = os.path.join(dirpath, filename)\n",
    "            target_folder = None\n",
    "            \n",
    "            if result.get('has_keywords'):\n",
    "                target_folder = 'price'\n",
    "            elif result.get('is_white'):\n",
    "                if result.get('text_lines', 0) >= 2:\n",
    "                    target_folder = 'txt'\n",
    "                else:\n",
    "                    target_folder = 'white'\n",
    "            elif result.get('text_lines', 0) >= 2:\n",
    "                target_folder = 'txt'\n",
    "            else:\n",
    "                target_folder = 'scene'\n",
    "                \n",
    "            if target_folder:\n",
    "                # 修复：使用source_path而不是img_path\n",
    "                target_path = os.path.join(os.path.dirname(source_path), target_folder, filename)\n",
    "                try:\n",
    "                    os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "                    shutil.move(source_path, target_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to move {filename}: {e}\")\n",
    "                    print(f\"From: {source_path}\")\n",
    "                    print(f\"To: {target_path}\")\n",
    "\n",
    "    # 主处理流程\n",
    "    for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "        if os.path.basename(dirpath) == 'grounding_output':\n",
    "            # 创建所需文件夹\n",
    "            for folder in ['price', 'txt', 'scene', 'white']:\n",
    "                os.makedirs(os.path.join(dirpath, folder), exist_ok=True)\n",
    "            \n",
    "            # 收集并处理图片\n",
    "            image_files = collect_images(dirpath)\n",
    "            if not image_files:\n",
    "                continue\n",
    "                \n",
    "            print(f\"Processing {len(image_files)} images in {dirpath}\")\n",
    "            results = batch_process_images(dirpath, image_files)\n",
    "            \n",
    "            # 批量移动文件\n",
    "            move_files_batch(dirpath, results)\n",
    "\n",
    "root_folder = f\"D://code//data//猫表数据//{z}\"\n",
    "process_folder(root_folder)\n",
    "\n",
    "\n",
    "# 获取当前时间\n",
    "current_time = datetime.now()\n",
    "\n",
    "# 打印当前时间\n",
    "print(\"当前系统时间是:\", current_time)\n",
    "print(\"当前系统时间是:\", current_time)\n",
    "print(\"当前系统时间是:\", current_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4846 images in D://code//data//猫表数据//猫表_男士休闲鞋\\grounding_output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  11%|█         | 544/4846 [06:10<58:56,  1.22it/s]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  11%|█▏        | 550/4846 [06:12<29:41,  2.41it/s]"
     ]
    }
   ],
   "source": [
    "# 这是更新方法, 先统一识别, 然后再一次性的移动\n",
    "# 增加了判断牛的条件, 当图片中出现文字, 且文字数量大于5个时, 就移动到txt文件夹\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from paddleocr import PaddleOCR\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "z = '猫表_男士休闲鞋'\n",
    "\n",
    "\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "\n",
    "def process_folder(root_folder):\n",
    "    # 1. 只初始化一次OCR\n",
    "    ocr = PaddleOCR(use_angle_cls=True, lang=\"ch\", show_log=False)\n",
    "    \n",
    "    # 2. 预先收集所有需要处理的图片\n",
    "    def collect_images(dirpath):\n",
    "        return [f for f in os.listdir(dirpath) if f.endswith(('.jpg', '.png'))]\n",
    "    \n",
    "    # 3. 优化白底图检测\n",
    "    def check_white_background(img, threshold=0.45, sample_rate=5):\n",
    "        \"\"\"使用采样方式检测白底，而不是遍历所有像素\"\"\"\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        width, height = img.size\n",
    "        white_pixels = 0\n",
    "        total_pixels = 0\n",
    "        \n",
    "        # 每隔sample_rate个像素采样一次\n",
    "        for x in range(0, width, sample_rate):\n",
    "            for y in range(0, height, sample_rate):\n",
    "                total_pixels += 1\n",
    "                r, g, b = img.getpixel((x, y))\n",
    "                if r > 230 and g > 230 and b > 230:\n",
    "                    white_pixels += 1\n",
    "                    \n",
    "        return (white_pixels / total_pixels) > threshold\n",
    "    \n",
    "    # 4. 优化OCR文本检测\n",
    "    def process_image_once(img_path):\n",
    "        \"\"\"一次性处理图片，返回所有需要的信息\"\"\"\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            width, height = img.size\n",
    "            \n",
    "            # 检查是否是白底图\n",
    "            is_white = check_white_background(img)\n",
    "            \n",
    "            # OCR处理\n",
    "            result = ocr.ocr(img_path, cls=True)\n",
    "            if not result or not result[0]:\n",
    "                return {'is_white': is_white}\n",
    "                \n",
    "            texts = [line[1][0] for line in result[0]]\n",
    "            text_heights = [abs(line[0][0][1] - line[0][3][1]) for line in result[0]]\n",
    "            \n",
    "            # 检查关键词\n",
    "            keywords = {'满', '减', '折', '到手价', '送', '免息', '活动价', '包邮价', \n",
    "                       '参考价', '券', '优惠', '用券', '领券', '送', '低至', \n",
    "                       '立减', '直降', '免息', '¥', '夫', '￥', '免费'}\n",
    "            has_keywords = any(any(k in text for k in keywords) for text in texts)\n",
    "            \n",
    "            # 统计文字数量和行数\n",
    "            total_chars = sum(len(text.strip()) for text in texts)\n",
    "            text_lines = len(texts)  # 统计文本行数\n",
    "            \n",
    "            return {\n",
    "                'is_white': is_white,\n",
    "                'has_keywords': has_keywords,\n",
    "                'text_count': total_chars,\n",
    "                'text_lines': text_lines,\n",
    "                'texts': texts\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # 5. 批量处理图片\n",
    "    def batch_process_images(dirpath, image_files):\n",
    "        results = {}\n",
    "        with tqdm(total=len(image_files), desc=\"Processing images\") as pbar:\n",
    "            for filename in image_files:\n",
    "                img_path = os.path.join(dirpath, filename)\n",
    "                results[filename] = process_image_once(img_path)\n",
    "                pbar.update(1)\n",
    "        return results\n",
    "    \n",
    "    # 6. 一次性移动文件\n",
    "    def move_files_batch(dirpath, results):\n",
    "        for filename, result in results.items():\n",
    "            if not result:\n",
    "                continue\n",
    "                \n",
    "            source_path = os.path.join(dirpath, filename)\n",
    "            target_folder = None\n",
    "            \n",
    "            if result.get('has_keywords'):\n",
    "                target_folder = 'price'\n",
    "            # 判断是否为txt：文字行数>1且文字数量>5\n",
    "            elif (result.get('text_lines', 0) > 1 and \n",
    "                  result.get('text_count', 0) > 5):\n",
    "                target_folder = 'txt'\n",
    "            # 判断是否为white：白色像素占比超过阈值\n",
    "            elif result.get('is_white', False):\n",
    "                target_folder = 'white'\n",
    "            else:\n",
    "                target_folder = 'scene'\n",
    "                \n",
    "            if target_folder:\n",
    "                target_path = os.path.join(os.path.dirname(source_path), target_folder, filename)\n",
    "                try:\n",
    "                    os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "                    shutil.move(source_path, target_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to move {filename}: {e}\")\n",
    "                    print(f\"From: {source_path}\")\n",
    "                    print(f\"To: {target_path}\")\n",
    "\n",
    "    # 主处理流程\n",
    "    for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "        if os.path.basename(dirpath) == 'grounding_output':\n",
    "            # 创建所需文件夹\n",
    "            for folder in ['price', 'txt', 'white', 'scene']:\n",
    "                os.makedirs(os.path.join(dirpath, folder), exist_ok=True)\n",
    "            \n",
    "            # 收集并处理图片\n",
    "            image_files = collect_images(dirpath)\n",
    "            if not image_files:\n",
    "                continue\n",
    "                \n",
    "            print(f\"Processing {len(image_files)} images in {dirpath}\")\n",
    "            results = batch_process_images(dirpath, image_files)\n",
    "            \n",
    "            # 批量移动文件\n",
    "            move_files_batch(dirpath, results)\n",
    "\n",
    "root_folder = f\"D://code//data//猫表数据//{z}\"\n",
    "process_folder(root_folder)\n",
    "\n",
    "\n",
    "# 获取当前时间\n",
    "current_time = datetime.now()\n",
    "\n",
    "# 打印当前时间\n",
    "print(\"当前系统时间是:\", current_time)\n",
    "print(\"当前系统时间是:\", current_time)\n",
    "print(\"当前系统时间是:\", current_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是新方法, 先统一识别, 然后再一次性的移动\n",
    "# 添加了一步流程, 将white文件夹中的图片再次处理, 如果有文本, 则移动到txt文件夹\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from paddleocr import PaddleOCR\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "z = '猫表_男士休闲鞋'\n",
    "\n",
    "\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "\n",
    "def process_folder(root_folder):\n",
    "    # 1. 只初始化一次OCR\n",
    "    ocr = PaddleOCR(use_angle_cls=True, lang=\"ch\", show_log=False)\n",
    "    \n",
    "    # 2. 预先收集所有需要处理的图片\n",
    "    def collect_images(dirpath):\n",
    "        return [f for f in os.listdir(dirpath) if f.endswith(('.jpg', '.png'))]\n",
    "    \n",
    "    # 3. 优化白底图检测\n",
    "    def check_white_background(img, threshold=0.45, sample_rate=5):\n",
    "        \"\"\"使用采样方式检测白底，而不是遍历所有像素\"\"\"\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        width, height = img.size\n",
    "        white_pixels = 0\n",
    "        total_pixels = 0\n",
    "        \n",
    "        # 每隔sample_rate个像素采样一次\n",
    "        for x in range(0, width, sample_rate):\n",
    "            for y in range(0, height, sample_rate):\n",
    "                total_pixels += 1\n",
    "                r, g, b = img.getpixel((x, y))\n",
    "                if r > 230 and g > 230 and b > 230:\n",
    "                    white_pixels += 1\n",
    "                    \n",
    "        return (white_pixels / total_pixels) > threshold\n",
    "    \n",
    "    # 4. 优化OCR文本检测\n",
    "    def process_image_once(img_path):\n",
    "        \"\"\"一次性处理图片，返回所有需要的信息\"\"\"\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            width, height = img.size\n",
    "            \n",
    "            # 检查是否是白底图\n",
    "            is_white = check_white_background(img)\n",
    "            \n",
    "            # OCR处理\n",
    "            result = ocr.ocr(img_path, cls=True)\n",
    "            if not result or not result[0]:\n",
    "                return {'is_white': is_white}\n",
    "                \n",
    "            texts = [line[1][0] for line in result[0]]\n",
    "            text_heights = [abs(line[0][0][1] - line[0][3][1]) for line in result[0]]\n",
    "            \n",
    "            # 检查关键词\n",
    "            keywords = {'满', '减', '折', '到手价', '送', '免息', '活动价', '包邮价', \n",
    "                       '参考价', '券', '优惠', '用券', '领券', '送', '低至', \n",
    "                       '立减', '直降', '免息', '¥', '夫', '￥', '免费'}\n",
    "            has_keywords = any(any(k in text for k in keywords) for text in texts)\n",
    "            \n",
    "            # 检查文本行数\n",
    "            text_lines = sum(1 for h in text_heights if h > 30)\n",
    "            \n",
    "            return {\n",
    "                'is_white': is_white,\n",
    "                'has_keywords': has_keywords,\n",
    "                'text_lines': text_lines,\n",
    "                'texts': texts\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # 5. 批量处理图片\n",
    "    def batch_process_images(dirpath, image_files):\n",
    "        results = {}\n",
    "        with tqdm(total=len(image_files), desc=\"Processing images\") as pbar:\n",
    "            for filename in image_files:\n",
    "                img_path = os.path.join(dirpath, filename)\n",
    "                results[filename] = process_image_once(img_path)\n",
    "                pbar.update(1)\n",
    "        return results\n",
    "    \n",
    "    # 6. 一次性移动文件\n",
    "    def move_files_batch(dirpath, results):\n",
    "        for filename, result in results.items():\n",
    "            if not result:\n",
    "                continue\n",
    "                \n",
    "            source_path = os.path.join(dirpath, filename)\n",
    "            target_folder = None\n",
    "            \n",
    "            if result.get('has_keywords'):\n",
    "                target_folder = 'price'\n",
    "            elif result.get('is_white'):\n",
    "                if result.get('text_lines', 0) >= 2:\n",
    "                    target_folder = 'txt'\n",
    "                else:\n",
    "                    target_folder = 'white'\n",
    "            elif result.get('text_lines', 0) >= 2:\n",
    "                target_folder = 'txt'\n",
    "            else:\n",
    "                target_folder = 'scene'\n",
    "                \n",
    "            if target_folder:\n",
    "                # 修复：使用source_path而不是img_path\n",
    "                target_path = os.path.join(os.path.dirname(source_path), target_folder, filename)\n",
    "                try:\n",
    "                    os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "                    shutil.move(source_path, target_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to move {filename}: {e}\")\n",
    "                    print(f\"From: {source_path}\")\n",
    "                    print(f\"To: {target_path}\")\n",
    "\n",
    "    # 处理white文件夹中的图片\n",
    "    def process_white_folder(dirpath, ocr):\n",
    "        \"\"\"处理white文件夹中的图片\"\"\"\n",
    "        white_folder = os.path.join(dirpath, 'white')\n",
    "        txt_folder = os.path.join(dirpath, 'txt')\n",
    "        \n",
    "        if not os.path.exists(white_folder):\n",
    "            print(\"White folder not found\")\n",
    "            return\n",
    "        \n",
    "        # 收集white文件夹中的图片\n",
    "        white_images = [f for f in os.listdir(white_folder) if f.endswith(('.jpg', '.png'))]\n",
    "        if not white_images:\n",
    "            print(\"No images found in white folder\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nProcessing {len(white_images)} images in white folder\")\n",
    "        \n",
    "        # 处理每张图片\n",
    "        with tqdm(total=len(white_images), desc=\"Checking white images\") as pbar:\n",
    "            for filename in white_images:\n",
    "                img_path = os.path.join(white_folder, filename)\n",
    "                try:\n",
    "                    # OCR处理\n",
    "                    result = ocr.ocr(img_path, cls=True)\n",
    "                    if result and result[0]:\n",
    "                        # 统计文本数量\n",
    "                        texts = [line[1][0] for line in result[0]]\n",
    "                        total_chars = sum(len(text.strip()) for text in texts)\n",
    "                        \n",
    "                        # 如果文本数量大于5，移动到txt文件夹\n",
    "                        if total_chars > 5:\n",
    "                            target_path = os.path.join(txt_folder, filename)\n",
    "                            try:\n",
    "                                shutil.move(img_path, target_path)\n",
    "                                # print(f\"\\nMoved {filename} to txt folder (text count: {total_chars})\")\n",
    "                            except Exception as e:\n",
    "                                # print(f\"\\nFailed to move {filename}: {e}\")\n",
    "                                pass\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError processing {filename}: {e}\")\n",
    "                finally:\n",
    "                    pbar.update(1)\n",
    "                    gc.collect()  # 及时清理内存\n",
    "\n",
    "    # 主处理流程\n",
    "    for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "        if os.path.basename(dirpath) == 'grounding_output':\n",
    "            # 创建所需文件夹\n",
    "            for folder in ['price', 'txt', 'scene', 'white']:\n",
    "                os.makedirs(os.path.join(dirpath, folder), exist_ok=True)\n",
    "            \n",
    "            # 收集并处理图片\n",
    "            image_files = collect_images(dirpath)\n",
    "            if not image_files:\n",
    "                continue\n",
    "                \n",
    "            # print(f\"Processing {len(image_files)} images in {dirpath}\")\n",
    "            results = batch_process_images(dirpath, image_files)\n",
    "            \n",
    "            # 批量移动文件\n",
    "            move_files_batch(dirpath, results)\n",
    "            \n",
    "            # 添加white文件夹的二次处理\n",
    "            # print(\"\\nStarting second-pass processing for white folder...\")\n",
    "            process_white_folder(dirpath, ocr)\n",
    "\n",
    "    # 清理OCR实例\n",
    "    del ocr\n",
    "    gc.collect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = datetime.now()\n",
    "    print(f\"Started at: {start_time}\")\n",
    "    \n",
    "    try:\n",
    "        root_folder = f\"D://code//data//猫表数据//{z}\"\n",
    "        process_folder(root_folder)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        end_time = datetime.now()\n",
    "        print(f\"Finished at: {end_time}\")\n",
    "        print(f\"Total time: {end_time - start_time}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 这里存放的是针对文本提取的优化逻辑, 暂时不知道放在哪里, 先放在这里\n",
    "# # 修改后的代码, 先从图片中识别出文本, 然后分两步\n",
    "# # ① 对文本框进行阈值下的合并; 同时也保留原文本框\n",
    "# # ② 对文本进行高度和关键词的分类\n",
    "\n",
    "\n",
    "\n",
    "# import os\n",
    "# import glob\n",
    "# from tqdm import tqdm\n",
    "# import pandas as pd\n",
    "# from paddleocr import PaddleOCR\n",
    "# from PIL import Image\n",
    "# import math\n",
    "# import re\n",
    "# import datetime\n",
    "# import multiprocessing\n",
    "# import gc\n",
    "\n",
    "\n",
    "\n",
    "# z = '猫表_测试_少量'\n",
    "\n",
    "\n",
    "# # 设置输入和输出路径\n",
    "# input_folder_path = f'D://code//data//猫表数据//{z}'\n",
    "# output_file_path = f'D://code//data//猫表数据//{z}//txt_info.xlsx'\n",
    "\n",
    "# def calculate_shortest_distance(point_a, points_bcd):\n",
    "#     shortest_distance = float('inf')\n",
    "#     for point_bcd in points_bcd:\n",
    "#         distance = ((point_bcd[0] - point_a[0]) ** 2 + (point_bcd[1] - point_a[1]) ** 2) ** 0.5\n",
    "#         if distance < shortest_distance:\n",
    "#             shortest_distance = distance\n",
    "#     return shortest_distance\n",
    "\n",
    "# def merge_text_boxes(img_path, style, ocr_instance):\n",
    "#     \"\"\"使用传入的OCR实例处理图片\"\"\"\n",
    "#     result = ocr_instance.ocr(img_path, cls=True)\n",
    "#     img = Image.open(img_path)\n",
    "#     img_width, img_height = img.size\n",
    "\n",
    "#     if not result or not result[0]:\n",
    "#         # print(f\"No text detected in the image: {img_path}\")\n",
    "#         return None, None\n",
    "\n",
    "#     rectangles_with_text = result[0]\n",
    "\n",
    "#     original_text_box_info = []\n",
    "#     for rectangle in rectangles_with_text:\n",
    "#         points = rectangle[0]\n",
    "#         original_text_box_info.append({\n",
    "#             'File Name': os.path.basename(img_path),\n",
    "#             'Style': style,\n",
    "#             'x1': points[0][0],\n",
    "#             'y1': points[0][1],\n",
    "#             'x2': points[2][0],\n",
    "#             'y2': points[2][1],\n",
    "#             'text': rectangle[1][0]\n",
    "#         })\n",
    "\n",
    "#     merged_text_boxes = []\n",
    "\n",
    "#     for index, row in pd.DataFrame(original_text_box_info).iterrows():\n",
    "#         if not merged_text_boxes:\n",
    "#             merged_text_boxes.append(row.to_dict())\n",
    "#         else:\n",
    "#             last_merged_box = merged_text_boxes[-1]\n",
    "\n",
    "#             if calculate_shortest_distance((row['x1'], row['y1']), [(last_merged_box['x1'], last_merged_box['y1']), (last_merged_box['x2'], last_merged_box['y1']), (last_merged_box['x2'], last_merged_box['y2']), (last_merged_box['x1'], last_merged_box['y2'])]) < 100:  # 设定文本框合并的阈值\n",
    "#                 last_merged_box['text'] += ' ' + row['text']\n",
    "#                 last_merged_box['x1'] = min(last_merged_box['x1'], row['x1'])\n",
    "#                 last_merged_box['y1'] = min(last_merged_box['y1'], row['y1'])\n",
    "#                 last_merged_box['x2'] = max(last_merged_box['x2'], row['x2'])\n",
    "#                 last_merged_box['y2'] = max(last_merged_box['y2'], row['y2'])\n",
    "#             else:\n",
    "#                 merged_text_boxes.append(row.to_dict())\n",
    "\n",
    "#     original_text_box_df = pd.DataFrame(original_text_box_info)\n",
    "#     merged_text_box_df = pd.DataFrame(merged_text_boxes)\n",
    "\n",
    "#     for i, box in original_text_box_df.iterrows():\n",
    "#         if box['y1'] < img_height / 2 and box['y2'] < img_height / 2:\n",
    "#             region = '上半'\n",
    "#         elif box['y1'] >= img_height / 2 and box['y2'] >= img_height / 2:\n",
    "#             region = '下半'\n",
    "#         elif box['x1'] < img_width / 2 and box['x2'] < img_width / 2:\n",
    "#             region = '左半'\n",
    "#         else:\n",
    "#             region = '右半'\n",
    "#         original_text_box_df.at[i, 'Region'] = region\n",
    "\n",
    "#         box_area = (box['x2'] - box['x1']) * (box['y2'] - box['y1'])\n",
    "#         box_per = box_area / (img_width * img_height)\n",
    "#         original_text_box_df.at[i, 'txt_Area'] = box_area\n",
    "#         original_text_box_df.at[i, 'txt_Per'] = box_per\n",
    "\n",
    "#     for i, box in merged_text_box_df.iterrows():\n",
    "#         if box['y1'] < img_height / 2 and box['y2'] < img_height / 2:\n",
    "#             region = '上半'\n",
    "#         elif box['y1'] >= img_height / 2 and box['y2'] >= img_height / 2:\n",
    "#             region = '下半'\n",
    "#         elif box['x1'] < img_width / 2 and box['x2'] < img_width / 2:\n",
    "#             region = '左半'\n",
    "#         else:\n",
    "#             region = '右半'\n",
    "#         merged_text_box_df.at[i, 'Region'] = region\n",
    "\n",
    "#         merge_area = (box['x2'] - box['x1']) * (box['y2'] - box['y1'])\n",
    "#         merge_per = merge_area / (img_width * img_height)\n",
    "#         merged_text_box_df.at[i, 'Area'] = merge_area\n",
    "#         merged_text_box_df.at[i, 'Per'] = merge_per\n",
    "\n",
    "#     return merged_text_box_df, original_text_box_df\n",
    "\n",
    "# keyword_groups = {\n",
    "#     '通用': ['以旧换新', '只换不修', '包邮', '无理由退', '先用后付', '京东白条', '期免息', '送货上门', '保修'],\n",
    "#     '价保': ['价保', '保价'],\n",
    "#     '纯价格': ['¥', '夫', '￥', r'\\b价\\b', '到手价', '活动价'],\n",
    "#     '直降': ['立减', '直降', '降', '立省', r'^(?!.*升降).*$', r'^(?!.*降温).*$', r'^(?!.*降噪).*$', r'^(?!.*降低).*$'],\n",
    "#     '折扣': ['折', r'^(?!.*折叠).*$', r'^(?!.*翻折).*$'],\n",
    "#     '满减': [r'.*满.*减.*', r'.*满.*-.*', r'.*满.*免.*'],\n",
    "#     '用券': ['用券', '领券', '券'],\n",
    "#     '返券': ['返券', '京豆', '返现', r'.*返.*E卡.*', r'.*返.*红包.*'],\n",
    "#     '限时': ['.*小时$', '.*天$', '时间', 'time', 'TIME', '限时', r'.*月.*日.*', r'.*日.*点.*', r'.*:.*', r'.*:.*', r'.*：.*', r'\\b\\d{1,2}\\.\\d{1,2}-\\d{1,2}\\b'],\n",
    "#     'xx元任选': [r'.*元.*件.*'],\n",
    "#     '赠品': [r'.*满.*赠.*', r'.*满.*送.*', '送', '抽', '奖励', '赠', r'^(?!.*送货).*$', r'^(?!.*送礼).*$', r'^(?!.*送装).*$', r'^(?!.*配送).*$', r'^(?!.*送达).*$'],\n",
    "#     '节日名称': ['节', '出游季', '购物季', '毕业季', '开学季', '黑五', '周年庆', '儿童节', '父亲节', '端午节', '七夕', '中秋节', '国庆', '万圣节', '感恩节', '元旦', '圣诞', '情人节', '春节', '元宵节', '38节', '3.8节', '清明节', '母亲节', '618', '购物季', '开学季', '11.11', '黑五', '12.12', '女神节', '出游季', '放价季', '吃货节', '家装节'],\n",
    "#     '是否限购': ['限购', '限量']\n",
    "# }\n",
    "\n",
    "# def keyword_analysis(text):\n",
    "#     results = {}\n",
    "#     for key, words in keyword_groups.items():\n",
    "#         results[key] = any(re.search(word, text) for word in words)\n",
    "#     return results\n",
    "\n",
    "# def height_analysis(x1, y1, x2, y2):\n",
    "#     height = abs(y2 - y1)\n",
    "#     return height\n",
    "\n",
    "# def process_image_batch(batch_data):\n",
    "#     \"\"\"处理一批图片\"\"\"\n",
    "#     try:\n",
    "#         # 在每个批次中创建OCR实例\n",
    "#         local_ocr = PaddleOCR(use_angle_cls=True, lang=\"ch\", show_log=False)\n",
    "#         batch_results = []\n",
    "        \n",
    "#         for img_path, style in batch_data:\n",
    "#             try:\n",
    "#                 # 将OCR实例传递给merge_text_boxes函数\n",
    "#                 merged_df, original_df = merge_text_boxes(img_path, style, local_ocr)\n",
    "#                 if merged_df is not None and original_df is not None:\n",
    "#                     batch_results.append({\n",
    "#                         'original': original_df,\n",
    "#                         'merged': merged_df\n",
    "#                     })\n",
    "#             except Exception as e:\n",
    "#                 print(f\"\\n处理图片出错 {img_path}: {str(e)}\")\n",
    "#                 continue\n",
    "                \n",
    "#         # 清理内存\n",
    "#         del local_ocr\n",
    "#         gc.collect()\n",
    "        \n",
    "#         return batch_results\n",
    "#     except Exception as e:\n",
    "#         print(f\"\\n批处理出错: {str(e)}\")\n",
    "#         return []\n",
    "\n",
    "# def process_images(input_folder_path):\n",
    "#     \"\"\"处理所有图片\"\"\"\n",
    "#     image_files = []\n",
    "    \n",
    "#     # 构建grounding_output路径\n",
    "#     grounding_output_path = os.path.join(input_folder_path, 'grounding_output')\n",
    "#     if not os.path.exists(grounding_output_path):\n",
    "#         print(f\"警告：{grounding_output_path} 文件夹不存在\")\n",
    "#         return []\n",
    "        \n",
    "#     # 收集所有图片路径\n",
    "#     for subfolder in ['price', 'txt']:\n",
    "#         subfolder_path = os.path.join(grounding_output_path, subfolder)\n",
    "#         if not os.path.exists(subfolder_path):\n",
    "#             print(f\"警告：{subfolder_path} 文件夹不存在\")\n",
    "#             continue\n",
    "            \n",
    "#         for file in os.listdir(subfolder_path):\n",
    "#             if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp')):\n",
    "#                 image_files.append((os.path.join(subfolder_path, file), subfolder))\n",
    "    \n",
    "#     if not image_files:\n",
    "#         print(f\"警告：在 {grounding_output_path} 中没有找到图片文件\")\n",
    "#         return []\n",
    "        \n",
    "#     print(f\"总共找到 {len(image_files)} 张图片\")\n",
    "    \n",
    "#     # 将图片分批，增加批次大小以减少进程切换开销\n",
    "#     batch_size = 5\n",
    "#     batches = [image_files[i:i + batch_size] for i in range(0, len(image_files), batch_size)]\n",
    "#     print(f\"将 {len(image_files)} 张图片分成 {len(batches)} 个批次，每批 {batch_size} 张\")\n",
    "    \n",
    "#     # 使用单进程处理所有图片\n",
    "#     print(\"\\n开始处理所有图片...\")\n",
    "#     combined_results = []\n",
    "    \n",
    "#     with tqdm(total=len(batches), desc=\"处理批次\", ncols=100) as pbar:\n",
    "#         for batch in batches:\n",
    "#             try:\n",
    "#                 result = process_image_batch(batch)\n",
    "#                 if result:\n",
    "#                     combined_results.extend(result)\n",
    "#                 pbar.update(1)\n",
    "#                 gc.collect()\n",
    "#             except Exception as e:\n",
    "#                 print(f\"\\n处理批次时出错: {str(e)}\")\n",
    "#                 continue\n",
    "    \n",
    "#     print(f\"\\n处理完成，总共成功处理 {len(combined_results)} 个结果\")\n",
    "#     return combined_results\n",
    "\n",
    "# # 主程序部分也需要相应修改\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         if not os.path.exists(input_folder_path):\n",
    "#             raise FileNotFoundError(f\"输入文件夹不存在: {input_folder_path}\")\n",
    "            \n",
    "#         os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "        \n",
    "#         print(f\"开始处理文件夹: {input_folder_path}\")\n",
    "        \n",
    "#         # 处理图片\n",
    "#         all_results = process_images(input_folder_path)\n",
    "        \n",
    "#         if not all_results:\n",
    "#             print(\"没有找到可处理的图片\")\n",
    "#             exit()\n",
    "            \n",
    "#         # 合并所有结果\n",
    "#         final_combined_data = []\n",
    "#         for result in all_results:\n",
    "#             result['original']['Type'] = 'Original'\n",
    "#             result['merged']['Type'] = 'Merged'\n",
    "#             combined = pd.concat([result['original'], result['merged']], ignore_index=True)\n",
    "#             final_combined_data.append(combined)\n",
    "\n",
    "#         final_combined_df = pd.concat(final_combined_data, ignore_index=True)\n",
    "#         final_combined_df.sort_values(by=['File Name', 'Type'], inplace=True)\n",
    "\n",
    "#         # 分析文本并添加关键词分类与高度\n",
    "#         for index, row in tqdm(final_combined_df.iterrows(), total=final_combined_df.shape[0], desc=\"分析文本\"):\n",
    "#             keyword_results = keyword_analysis(row['text'])\n",
    "#             for key, value in keyword_results.items():\n",
    "#                 final_combined_df.at[index, key] = value\n",
    "            \n",
    "#             height = height_analysis(row['x1'], row['y1'], row['x2'], row['y2'])\n",
    "#             final_combined_df.at[index, 'Height'] = height\n",
    "#             final_combined_df.at[index, 'Height_Category'] = (\n",
    "#                 'Height_<18' if height < 18 else\n",
    "#                 'Height_18-29' if 18 <= height < 29 else\n",
    "#                 'Height_29-38' if 29 <= height < 38 else\n",
    "#                 'Height_>38'\n",
    "#             )\n",
    "\n",
    "#         # 保存结果\n",
    "#         final_combined_df.to_excel(output_file_path, index=False)\n",
    "#         print('处理完成')\n",
    "        \n",
    "#         # 打印完成时间\n",
    "#         current_time = datetime.datetime.now()\n",
    "#         formatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "#         print(f\"完成时间: {formatted_time}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"程序执行出错: {str(e)}\")\n",
    "#         raise\n",
    "#     finally:\n",
    "#         gc.collect()  # 最终清理\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step2.1 - 对四分类的数据总结\n",
    "### 针对整体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "统计结果 for 12066:\n",
      "  scene: 图片数量 = 3, UV = 119, Click UV = 9, CTR = 0.0756\n",
      "\n",
      "统计结果 for 6908:\n",
      "  price: 图片数量 = 462, UV = 1997399, Click UV = 75119, CTR = 0.0376\n",
      "  txt: 图片数量 = 120, UV = 2777440, Click UV = 90451, CTR = 0.0326\n",
      "  scene: 图片数量 = 721, UV = 14113428, Click UV = 461185, CTR = 0.0327\n",
      "  white: 图片数量 = 246, UV = 2132073, Click UV = 76381, CTR = 0.0358\n",
      "\n",
      "统计结果 for 6909:\n",
      "  price: 图片数量 = 446, UV = 787151, Click UV = 28230, CTR = 0.0359\n",
      "  txt: 图片数量 = 275, UV = 2535197, Click UV = 100304, CTR = 0.0396\n",
      "  scene: 图片数量 = 556, UV = 6398186, Click UV = 275823, CTR = 0.0431\n",
      "  white: 图片数量 = 263, UV = 1562568, Click UV = 60597, CTR = 0.0388\n",
      "\n",
      "统计结果 for 6910:\n",
      "  price: 图片数量 = 63, UV = 50103, Click UV = 2934, CTR = 0.0586\n",
      "  txt: 图片数量 = 169, UV = 844799, Click UV = 27781, CTR = 0.0329\n",
      "  scene: 图片数量 = 242, UV = 1738848, Click UV = 74195, CTR = 0.0427\n",
      "  white: 图片数量 = 261, UV = 497952, Click UV = 20120, CTR = 0.0404\n",
      "\n",
      "统计结果 for 6911:\n",
      "  price: 图片数量 = 50, UV = 1135608, Click UV = 54777, CTR = 0.0482\n",
      "  txt: 图片数量 = 299, UV = 4190983, Click UV = 156542, CTR = 0.0374\n",
      "  scene: 图片数量 = 360, UV = 10489691, Click UV = 398049, CTR = 0.0379\n",
      "  white: 图片数量 = 185, UV = 3788141, Click UV = 158589, CTR = 0.0419\n",
      "\n",
      "统计结果 for 6912:\n",
      "  price: 图片数量 = 755, UV = 380245, Click UV = 16481, CTR = 0.0433\n",
      "  txt: 图片数量 = 88, UV = 242284, Click UV = 11687, CTR = 0.0482\n",
      "  scene: 图片数量 = 723, UV = 1168290, Click UV = 49293, CTR = 0.0422\n",
      "  white: 图片数量 = 345, UV = 371182, Click UV = 15245, CTR = 0.0411\n",
      "\n",
      "统计结果 for 6913:\n",
      "  price: 图片数量 = 209, UV = 966789, Click UV = 52207, CTR = 0.0540\n",
      "  txt: 图片数量 = 471, UV = 1380509, Click UV = 78914, CTR = 0.0572\n",
      "  scene: 图片数量 = 222, UV = 919926, Click UV = 42097, CTR = 0.0458\n",
      "  white: 图片数量 = 178, UV = 389416, Click UV = 17690, CTR = 0.0454\n",
      "\n",
      "统计结果 for 9783:\n",
      "  scene: 图片数量 = 5, UV = 1577, Click UV = 69, CTR = 0.0438\n",
      "  white: 图片数量 = 2, UV = 54, Click UV = 4, CTR = 0.0741\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\12066_brand_all_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\6908_brand_all_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\6909_brand_all_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\6910_brand_all_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\6911_brand_all_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\6912_brand_all_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\6913_brand_all_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\9783_brand_all_url_1_chart.png\n",
      "统计结果已保存至Excel文件: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\brand_all_url_1_chart.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "\n",
    "# 所有的通用变量都放在这里,方便管理\n",
    "x_list = ['6908','6909','6910','6911','6912','6913','9783','12066']\n",
    "y_list = ['txt', 'price']\n",
    "path = 'Lv2期结论'\n",
    "z = '男鞋_from_0501'\n",
    "\n",
    "# 定义基础路径和CSV文件路径\n",
    "base_path = f'D://code//data//Lv2期结论//{z}'\n",
    "csv_file_path = f'D://code//data//Lv2期结论//{z}//{z}.csv'\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "def extract_matching_part(img_url):\n",
    "    if pd.isna(img_url):\n",
    "        return None\n",
    "    img_url = img_url.split('?')[0]\n",
    "    img_url = os.path.splitext(img_url)[0]\n",
    "    parts = img_url.split('/')\n",
    "    if len(parts) >= 2:\n",
    "        return f\"{parts[-2]}_{parts[-1]}\"\n",
    "    return None\n",
    "\n",
    "df['matching_part'] = df['img_url'].apply(extract_matching_part)\n",
    "\n",
    "def process_grounding_folder(grounding_path):\n",
    "    folder_stats = {\n",
    "        'price': {'count': 0, 'uv': 0, 'click_uv': 0},\n",
    "        'txt': {'count': 0, 'uv': 0, 'click_uv': 0},\n",
    "        'scene': {'count': 0, 'uv': 0, 'click_uv': 0},\n",
    "        'white': {'count': 0, 'uv': 0, 'click_uv': 0}\n",
    "    }\n",
    "\n",
    "    for folder_name in ['price', 'txt', 'scene', 'white']:\n",
    "        folder_path = os.path.join(grounding_path, folder_name)\n",
    "        if os.path.exists(folder_path):\n",
    "            for filename in os.listdir(folder_path):\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "                    filename_without_ext = os.path.splitext(filename)[0]\n",
    "                    filtered_df = df[df['matching_part'] == filename_without_ext]\n",
    "                    if not filtered_df.empty:\n",
    "                        folder_stats[folder_name]['count'] += 1\n",
    "                        folder_stats[folder_name]['uv'] += filtered_df['uv'].sum()\n",
    "                        folder_stats[folder_name]['click_uv'] += filtered_df['click_uv'].sum()\n",
    "\n",
    "    # 计算每个文件夹的CTR\n",
    "    for folder in folder_stats:\n",
    "        if folder_stats[folder]['uv'] > 0:\n",
    "            folder_stats[folder]['ctr'] = folder_stats[folder]['click_uv'] / folder_stats[folder]['uv']\n",
    "        else:\n",
    "            folder_stats[folder]['ctr'] = 0\n",
    "\n",
    "    return folder_stats\n",
    "\n",
    "all_stats = {}\n",
    "\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    if 'grounding_output' in dirs:\n",
    "        grounding_path = os.path.join(root, 'grounding_output')\n",
    "        folder_name = os.path.basename(root)\n",
    "        stats = process_grounding_folder(grounding_path)\n",
    "        all_stats[folder_name] = stats\n",
    "\n",
    "# 创建一个Excel工作簿来保存结果\n",
    "workbook = openpyxl.Workbook()\n",
    "sheet = workbook.active\n",
    "sheet.title = \"Image Distribution Stats\"\n",
    "\n",
    "# 写入表头\n",
    "headers = [\"Folder\", \"Subfolder\", \"Count\", \"UV\", \"Click UV\", \"CTR\", \"Brand\"]\n",
    "for col, header in enumerate(headers, start=1):\n",
    "    sheet.cell(row=1, column=col, value=header)\n",
    "\n",
    "row = 2  # 从第二行开始写入数据\n",
    "\n",
    "# 检查并创建url_1文件夹\n",
    "output_folder = os.path.join(base_path, 'url_1')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 输出统计结果\n",
    "for folder, stats in all_stats.items():\n",
    "    print(f\"\\n统计结果 for {folder}:\")\n",
    "    for subfolder, data in stats.items():\n",
    "        if data['count'] > 0:\n",
    "            ctr = data['click_uv'] / data['uv'] if data['uv'] > 0 else 0\n",
    "            print(f\"  {subfolder}: 图片数量 = {data['count']}, UV = {data['uv']}, Click UV = {data['click_uv']}, CTR = {ctr:.4f}\")\n",
    "\n",
    "# 定义颜色映射\n",
    "color_map = {\n",
    "    'price': '#FF6B6B',  # 柔和的红色\n",
    "    'txt': '#4ECDC4',    # 青绿色\n",
    "    'scene': '#7986CB',  # 淡紫色\n",
    "    'white': '#FFD93D'   # 明亮的黄色\n",
    "}\n",
    "\n",
    "# 绘制每个grounding_output文件夹的饼图并保存数据\n",
    "for folder, stats in all_stats.items():\n",
    "    counts = [data['count'] for data in stats.values() if data['count'] > 0]\n",
    "    labels = [subfolder for subfolder, data in stats.items() if data['count'] > 0]\n",
    "    ctrs = [data['ctr'] for data in stats.values() if data['count'] > 0]\n",
    "    colors = [color_map.get(label, 'gray') for label in labels]  # 使用颜色映射，如果没有指定则默认为灰色\n",
    "    \n",
    "    if counts:  # 只有当有数据时才绘图\n",
    "        plt.figure(figsize=(12, 9))\n",
    "        wedges, texts, autotexts = plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "        \n",
    "        # 添加数量和CTR标签\n",
    "        for i, (autotext, ctr) in enumerate(zip(autotexts, ctrs)):\n",
    "            autotext.set_text(f'{autotext.get_text()}\\n({counts[i]})\\nCTR: {ctr:.4f}')\n",
    "        \n",
    "        plt.title(f\"Image Distribution in {folder}\")\n",
    "        plt.axis('equal')\n",
    "\n",
    "        # 添加图例\n",
    "        plt.legend(wedges, [f\"{label} ({count}, CTR: {ctr:.4f})\" for label, count, ctr in zip(labels, counts, ctrs)],\n",
    "                    title=\"Categories\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "        \n",
    "        output_chart_path = os.path.join(output_folder, f'{folder}_brand_all_url_1_chart.png')\n",
    "        plt.savefig(output_chart_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"饼图已保存至: {output_chart_path}\")\n",
    "\n",
    "        # 写入数据到Excel, 添加品牌列 \"brand\" 的值为 \"all\"\n",
    "        for subfolder, data in stats.items():\n",
    "            if data['count'] > 0:\n",
    "                sheet.cell(row=row, column=1, value=folder)\n",
    "                sheet.cell(row=row, column=2, value=subfolder)\n",
    "                sheet.cell(row=row, column=3, value=data['count'])\n",
    "                sheet.cell(row=row, column=4, value=data['uv'])\n",
    "                sheet.cell(row=row, column=5, value=data['click_uv'])\n",
    "                sheet.cell(row=row, column=6, value=data['ctr'])\n",
    "                sheet.cell(row=row, column=7, value=\"all\")  # 添加品牌列，值为 \"all\"\n",
    "                row += 1\n",
    "\n",
    "# 保存Excel文件\n",
    "excel_output_path = os.path.join(output_folder, f'brand_all_url_1_chart.xlsx')\n",
    "workbook.save(excel_output_path)\n",
    "print(f\"统计结果已保存至Excel文件: {excel_output_path}\")\n",
    "\n",
    "import datetime\n",
    "current_time = datetime.datetime.now()\n",
    "formatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"完成时间: {formatted_time}\")\n",
    "print(f\"完成时间: {formatted_time}\")\n",
    "print(f\"完成时间: {formatted_time}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step2.2 - 对四分类的数据总结\n",
    "### 针对brand进行了分成的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heyunshen\\AppData\\Local\\Temp\\ipykernel_31720\\1564597199.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['matching_part'] = filtered_df['img_url'].apply(extract_matching_part)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6908_brand_1.0_2.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6909_brand_1.0_2.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6910_brand_1.0_2.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6911_brand_1.0_2.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6912_brand_1.0_2.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6913_brand_1.0_2.0_url_1_chart.png\n",
      "统计结果已保存至Excel文件: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//brand_1.0_2.0_url_1_chart.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heyunshen\\AppData\\Local\\Temp\\ipykernel_31720\\1564597199.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['matching_part'] = filtered_df['img_url'].apply(extract_matching_part)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6908_brand_3.0_4.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6909_brand_3.0_4.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6910_brand_3.0_4.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6911_brand_3.0_4.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6912_brand_3.0_4.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6913_brand_3.0_4.0_url_1_chart.png\n",
      "统计结果已保存至Excel文件: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//brand_3.0_4.0_url_1_chart.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heyunshen\\AppData\\Local\\Temp\\ipykernel_31720\\1564597199.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['matching_part'] = filtered_df['img_url'].apply(extract_matching_part)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//12066_brand_5.0_6.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6908_brand_5.0_6.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6909_brand_5.0_6.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6910_brand_5.0_6.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6911_brand_5.0_6.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6912_brand_5.0_6.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6913_brand_5.0_6.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//9783_brand_5.0_6.0_url_1_chart.png\n",
      "统计结果已保存至Excel文件: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//brand_5.0_6.0_url_1_chart.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "\n",
    "# 定义基础路径和CSV文件路径\n",
    "# z = '男士春夏下装_from_0501'\n",
    "base_path = f'D://code//data//Lv2期结论//{z}'\n",
    "csv_file_path = f'D://code//data//Lv2期结论//{z}//{z}.csv'\n",
    "brand_path = f'D://code//data//Lv2期结论//{z}//男鞋品牌分层.xlsx'\n",
    "\n",
    "# filter_layer_cases = [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]\n",
    "filter_layer_cases = [[1.0, 2.0],[3.0, 4.0], [5.0, 6.0]]\n",
    "\n",
    "\n",
    "for filter_layers in filter_layer_cases:\n",
    "    # 格式化 filter_layers\n",
    "    filter_layers_str = \"_\".join(map(str, filter_layers))\n",
    "\n",
    "    # 读取CSV文件和品牌分类文件\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df_brand = pd.read_excel(brand_path)\n",
    "\n",
    "    # 合并品牌信息\n",
    "    df = pd.merge(df, df_brand, on='main_brand_code', how='left')\n",
    "\n",
    "    # 筛选数据\n",
    "    filtered_df = df[df['最终分层'].isin(filter_layers)]\n",
    "\n",
    "    def extract_matching_part(img_url):\n",
    "        if pd.isna(img_url):\n",
    "            return None\n",
    "        img_url = img_url.split('?')[0]\n",
    "        img_url = os.path.splitext(img_url)[0]\n",
    "        parts = img_url.split('/')\n",
    "        if len(parts) >= 2:\n",
    "            return f\"{parts[-2]}_{parts[-1]}\"\n",
    "        return None\n",
    "\n",
    "    filtered_df['matching_part'] = filtered_df['img_url'].apply(extract_matching_part)\n",
    "\n",
    "    def process_grounding_folder(grounding_path):\n",
    "        folder_stats = {\n",
    "            'price': {'count': 0, 'uv': 0, 'click_uv': 0},\n",
    "            'txt': {'count': 0, 'uv': 0, 'click_uv': 0},\n",
    "            'scene': {'count': 0, 'uv': 0, 'click_uv': 0},\n",
    "            'white': {'count': 0, 'uv': 0, 'click_uv': 0}\n",
    "        }\n",
    "\n",
    "        for folder_name in ['price', 'txt', 'scene', 'white']:\n",
    "            folder_path = os.path.join(grounding_path, folder_name)\n",
    "            if os.path.exists(folder_path):\n",
    "                for filename in os.listdir(folder_path):\n",
    "                    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "                        filename_without_ext = os.path.splitext(filename)[0]\n",
    "                        folder_filtered_df = filtered_df[filtered_df['matching_part'] == filename_without_ext]\n",
    "                        if not folder_filtered_df.empty:\n",
    "                            folder_stats[folder_name]['count'] += 1\n",
    "                            folder_stats[folder_name]['uv'] += folder_filtered_df['uv'].sum()\n",
    "                            folder_stats[folder_name]['click_uv'] += folder_filtered_df['click_uv'].sum()\n",
    "\n",
    "        # 计算每个文件夹的CTR\n",
    "        for folder in folder_stats:\n",
    "            if folder_stats[folder]['uv'] > 0:\n",
    "                folder_stats[folder]['ctr'] = folder_stats[folder]['click_uv'] / folder_stats[folder]['uv']\n",
    "            else:\n",
    "                folder_stats[folder]['ctr'] = 0\n",
    "\n",
    "        return folder_stats\n",
    "\n",
    "    all_stats = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        if 'grounding_output' in dirs:\n",
    "            grounding_path = os.path.join(root, 'grounding_output')\n",
    "            folder_name = os.path.basename(root)\n",
    "            stats = process_grounding_folder(grounding_path)\n",
    "            all_stats[folder_name] = stats\n",
    "\n",
    "    # 定义颜色映射\n",
    "    color_map = {\n",
    "        'price': '#FF6B6B',  # 柔和的红色\n",
    "        'txt': '#4ECDC4',    # 青绿色\n",
    "        'scene': '#7986CB',  # 淡紫色\n",
    "        'white': '#FFD93D'   # 明亮的黄色\n",
    "    }\n",
    "\n",
    "    # 绘制饼图\n",
    "    for folder, stats in all_stats.items():\n",
    "        counts = [data['count'] for data in stats.values() if data['count'] > 0]\n",
    "        labels = [subfolder for subfolder, data in stats.items() if data['count'] > 0]\n",
    "        ctrs = [data['ctr'] for data in stats.values() if data['count'] > 0]\n",
    "        colors = [color_map.get(label, 'gray') for label in labels]  # 使用颜色映射，如果没有指定则默认为灰色\n",
    "        \n",
    "        if counts:  # 只有当有数据时才绘图\n",
    "            plt.figure(figsize=(12, 9))\n",
    "            wedges, texts, autotexts = plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "            \n",
    "            # 添加数量和CTR标签\n",
    "            for i, (autotext, ctr) in enumerate(zip(autotexts, ctrs)):\n",
    "                autotext.set_text(f'{autotext.get_text()}\\n({counts[i]})\\nCTR: {ctr:.4f}')\n",
    "            \n",
    "            plt.title(f\"Image Distribution in {folder} ({filter_layers_str})\")\n",
    "            plt.axis('equal')\n",
    "            \n",
    "            # 添加图例\n",
    "            plt.legend(wedges, [f\"{label} ({count}, CTR: {ctr:.4f})\" for label, count, ctr in zip(labels, counts, ctrs)],\n",
    "                       title=\"Categories\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "            \n",
    "            output_chart_path = os.path.join(base_path, f'url_1//{folder}_brand_{filter_layers_str}_url_1_chart.png')\n",
    "            plt.savefig(output_chart_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"饼图已保存至: {output_chart_path}\")\n",
    "\n",
    "    # 创建一个Excel工作簿来保存结果\n",
    "    workbook = openpyxl.Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = f\"Stats ({filter_layers_str})\"\n",
    "\n",
    "    # 写入表头\n",
    "    headers = [\"Folder\", \"Subfolder\", \"Count\", \"UV\", \"Click UV\", \"CTR\", \"Brand\"]\n",
    "    for col, header in enumerate(headers, start=1):\n",
    "        sheet.cell(row=1, column=col, value=header)\n",
    "\n",
    "    row = 2  # 从第二行开始写入数据\n",
    "\n",
    "    # 写入统计数据\n",
    "    for folder, stats in all_stats.items():\n",
    "        for subfolder, data in stats.items():\n",
    "            if data['count'] > 0:\n",
    "                sheet.cell(row=row, column=1, value=folder)\n",
    "                sheet.cell(row=row, column=2, value=subfolder)\n",
    "                sheet.cell(row=row, column=3, value=data['count'])\n",
    "                sheet.cell(row=row, column=4, value=data['uv'])\n",
    "                sheet.cell(row=row, column=5, value=data['click_uv'])\n",
    "                sheet.cell(row=row, column=6, value=data['ctr'])\n",
    "                sheet.cell(row=row, column=7, value=filter_layers_str)  # 添加品牌列，值为格式化后的筛选条件\n",
    "                row += 1\n",
    "\n",
    "    # 保存Excel文件\n",
    "    output_folder = os.path.join(base_path)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    excel_output_path = os.path.join(output_folder, f'url_1//brand_{filter_layers_str}_url_1_chart.xlsx')\n",
    "    workbook.save(excel_output_path)\n",
    "    print(f\"统计结果已保存至Excel文件: {excel_output_path}\")\n",
    "\n",
    "import datetime\n",
    "current_time = datetime.datetime.now()\n",
    "formatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"完成时间: {formatted_time}\")\n",
    "print(f\"完成时间: {formatted_time}\")\n",
    "print(f\"完成时间: {formatted_time}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将分类结果统计为excel文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 指定要拼接的Excel文件路径列表\n",
    "excel_file_paths = [\n",
    "    f\"D://code//data//Lv2期结论//{z}//url_1//brand_all_url_1_chart.xlsx\",\n",
    "    f\"D://code//data//Lv2期结论//{z}//url_1//brand_1.0_2.0_3.0_url_1_chart.xlsx\",\n",
    "    f\"D://code//data//Lv2期结论//{z}//url_1//brand_1.0_2.0_3.0_url_1_chart.xlsx\",\n",
    "    f\"D://code//data//Lv2期结论//{z}//url_1//brand_4.0_5.0_6.0_url_1_chart.xlsx\"\n",
    "]\n",
    "\n",
    "# 用于存储读取的每个Excel文件的数据框\n",
    "dataframes = []\n",
    "\n",
    "# 逐个读取指定的Excel文件并添加到dataframes列表中\n",
    "for file_path in excel_file_paths:\n",
    "    df = pd.read_excel(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# 将所有数据框上下拼接在一起\n",
    "merged_df = pd.concat(dataframes, axis=0, ignore_index=True)\n",
    "\n",
    "# 可以根据需要将拼接后的结果保存为新的Excel文件\n",
    "merged_df.to_excel(f\"D://code//data//Lv2期结论//{z}//url_1//all_url_1_chart.xlsx\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# # 存储图片信息的列表\n",
    "# image_info = []\n",
    "\n",
    "\n",
    "# # x = '京喜_from_0501'\n",
    "\n",
    "\n",
    "# # 一级文件夹路径\n",
    "# root_folder = f'D://code//data//Lv2期结论//{x}//筛选'\n",
    "\n",
    "\n",
    "\n",
    "# # 遍历一级文件夹下的所有二级文件夹\n",
    "# for sub_folder in os.listdir(root_folder):\n",
    "#     if sub_folder.isdigit():  # 只处理数字命名的二级文件夹\n",
    "#         grounding_folder = os.path.join(root_folder, sub_folder, 'grounding_output')\n",
    "#         if os.path.exists(grounding_folder):\n",
    "#             for sub_sub_folder in ['price', 'txt', 'white', 'scene']:\n",
    "#                 sub_sub_folder_path = os.path.join(grounding_folder, sub_sub_folder)\n",
    "#                 if os.path.exists(sub_sub_folder_path):\n",
    "#                     for image_file in os.listdir(sub_sub_folder_path):\n",
    "#                         if \"txt_\" in image_file:\n",
    "#                             image_file = image_file.replace(\"txt_\", \"\")\n",
    "#                         elif \"price_\" in image_file:\n",
    "#                             image_file = image_file.replace(\"price_\", \"\")\n",
    "#                         image_info.append([image_file, sub_sub_folder, sub_folder])\n",
    "\n",
    "# # 创建DataFrame并保存为Excel\n",
    "# df = pd.DataFrame(image_info, columns=['图片名', '分类', 'cid3'])\n",
    "# # df.to_excel('D://code//data//Lv2期结论//京喜_from_0501//筛选//分类数据image_info.xlsx', index=False)\n",
    "\n",
    "# # 读取Excel文件\n",
    "# # data = pd.read_csv('D://code//data//Lv2期结论//京喜_from_0501//京喜数据_from_0501_筛选.csv')\n",
    "# # df2 = pd.read_csv('D://code//data//Lv2期结论//京喜_from_0501//京喜数据_from_0501_筛选.csv')\n",
    "\n",
    "# df2 = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # 按照img_url列进行聚合，并对指定列进行求和\n",
    "# aggregated_data = df2.groupby('img_url').agg({\n",
    "#     'uv':'sum',\n",
    "#     'click_uv':'sum',\n",
    "#     'gmv_cj':'sum',\n",
    "#     'sale_qtty_cj':'sum'\n",
    "# }).reset_index()\n",
    "\n",
    "# # 将原始数据中与聚合相关的列合并到聚合后的数据中\n",
    "# aggregated_data = pd.merge(aggregated_data, df2[['sku', 'img_url','img_type', 'bu_id', 'cid1', 'cid2', 'cid3', 'main_brand_code','shop_id']], on='img_url', how='left')\n",
    "\n",
    "# # 保存为新的Excel文件\n",
    "# # aggregated_data.to_excel('D://code//data//Lv2期结论//京喜_from_0501//url加总原始数据.xlsx', index=False)\n",
    "# # csv_file_path = 'D://code//data//Lv2期结论//京喜_from_0501//url加总原始数据.xlsx'\n",
    "# # df = pd.read_excel(csv_file_path)\n",
    "\n",
    "# def extract_matching_part(img_url):\n",
    "#     if pd.isna(img_url):\n",
    "#         return None\n",
    "#     img_url = img_url.split('?')[0]\n",
    "#     img_url = os.path.splitext(img_url)[0]\n",
    "#     parts = img_url.split('/')\n",
    "#     if len(parts) >= 2:\n",
    "#         return f\"{parts[-2]}_{parts[-1]}\"\n",
    "#     return None\n",
    "\n",
    "# aggregated_data['matching_part'] = aggregated_data['img_url'].apply(extract_matching_part)\n",
    "\n",
    "# # df_x = pd.read_excel('D://code//data//Lv2期结论//京喜_from_0501//筛选//分类数据image_info.xlsx')\n",
    "\n",
    "# # 确保列数据类型匹配（如果需要）\n",
    "# aggregated_data['matching_part'] = aggregated_data['matching_part'].astype(str)\n",
    "# df['图片名'] = df['图片名'].apply(lambda x: str(x).replace('.jpg', '') if isinstance(x, (str, bytes)) else x)\n",
    "\n",
    "# # 根据条件进行拼接\n",
    "# merged_df = pd.merge(aggregated_data, df, left_on='matching_part', right_on='图片名', how='right')\n",
    "# merged_df.to_excel(f'D://code//data//Lv2期结论//{x}//sku分类数据表.xlsx', index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
