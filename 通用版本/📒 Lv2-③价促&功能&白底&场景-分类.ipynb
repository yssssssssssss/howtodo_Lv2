{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step1 - 对图片进行分类(price/txt/white/scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: 筛选价促卖点图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 3/3 [00:01<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卖点图 classification completed.\n",
      "完成时间: 2024-10-25 10:44:21.967672\n",
      "Step 2: 筛选白底图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving images from D://code//data//Lv2期结论//男鞋_from_0501\\12066\\grounding_output: 100%|██████████| 3/3 [00:00<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成时间: 2024-10-25 10:44:22.743692\n",
      "Step 3: 筛选功能卖点图\n",
      "Step 4: 归类图片到 scene\n",
      "Image moving completed.\n",
      "完成时间: 2024-10-25 10:44:23.433699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image classification completed.\n",
      "okkk\n",
      "当前系统时间是: 2024-10-25 10:44:23.445910\n",
      "当前系统时间是: 2024-10-25 10:44:23.445910\n",
      "当前系统时间是: 2024-10-25 10:44:23.445910\n",
      "Step 1: 筛选价促卖点图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 1549/1549 [15:30<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卖点图 classification completed.\n",
      "完成时间: 2024-10-25 10:59:54.293389\n",
      "Step 2: 筛选白底图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving images from D://code//data//Lv2期结论//男鞋_from_0501\\6908\\grounding_output: 100%|██████████| 1087/1087 [04:32<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成时间: 2024-10-25 11:04:26.425259\n",
      "Step 3: 筛选功能卖点图\n",
      "Step 4: 归类图片到 scene\n",
      "Image moving completed.\n",
      "完成时间: 2024-10-25 11:08:16.630374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   4%|▍         | 11/257 [00:58<21:55,  5.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image classification completed.\n",
      "okkk\n",
      "当前系统时间是: 2024-10-25 11:09:15.468869\n",
      "当前系统时间是: 2024-10-25 11:09:15.468869\n",
      "当前系统时间是: 2024-10-25 11:09:15.468869\n",
      "Step 1: 筛选价促卖点图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 1540/1540 [28:48<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卖点图 classification completed.\n",
      "完成时间: 2024-10-25 11:38:03.716722\n",
      "Step 2: 筛选白底图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving images from D://code//data//Lv2期结论//男鞋_from_0501\\6909\\grounding_output: 100%|██████████| 1094/1094 [07:11<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成时间: 2024-10-25 11:45:15.048260\n",
      "Step 3: 筛选功能卖点图\n",
      "Step 4: 归类图片到 scene\n",
      "Image moving completed.\n",
      "完成时间: 2024-10-25 11:53:35.780953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   6%|▋         | 18/281 [02:26<35:43,  8.15s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image classification completed.\n",
      "okkk\n",
      "当前系统时间是: 2024-10-25 11:56:02.506917\n",
      "当前系统时间是: 2024-10-25 11:56:02.506917\n",
      "当前系统时间是: 2024-10-25 11:56:02.506917\n",
      "Step 1: 筛选价促卖点图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 735/735 [14:11<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卖点图 classification completed.\n",
      "完成时间: 2024-10-25 12:10:13.706556\n",
      "Step 2: 筛选白底图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving images from D://code//data//Lv2期结论//男鞋_from_0501\\6910\\grounding_output: 100%|██████████| 672/672 [04:22<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成时间: 2024-10-25 12:14:35.746579\n",
      "Step 3: 筛选功能卖点图\n",
      "Step 4: 归类图片到 scene\n",
      "Image moving completed.\n",
      "完成时间: 2024-10-25 12:20:36.395838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   3%|▎         | 7/268 [02:40<1:40:00, 22.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image classification completed.\n",
      "okkk\n",
      "当前系统时间是: 2024-10-25 12:23:17.356484\n",
      "当前系统时间是: 2024-10-25 12:23:17.356484\n",
      "当前系统时间是: 2024-10-25 12:23:17.356484\n",
      "Step 1: 筛选价促卖点图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 894/894 [20:19<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卖点图 classification completed.\n",
      "完成时间: 2024-10-25 12:43:36.926607\n",
      "Step 2: 筛选白底图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving images from D://code//data//Lv2期结论//男鞋_from_0501\\6911\\grounding_output: 100%|██████████| 844/844 [05:29<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成时间: 2024-10-25 12:49:06.722476\n",
      "Step 3: 筛选功能卖点图\n",
      "Step 4: 归类图片到 scene\n",
      "Image moving completed.\n",
      "完成时间: 2024-10-25 13:02:00.284146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  19%|█▊        | 42/227 [03:16<14:27,  4.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image classification completed.\n",
      "okkk\n",
      "当前系统时间是: 2024-10-25 13:05:17.216087\n",
      "当前系统时间是: 2024-10-25 13:05:17.216087\n",
      "当前系统时间是: 2024-10-25 13:05:17.216087\n",
      "Step 1: 筛选价促卖点图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 1911/1911 [51:16<00:00,  1.61s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卖点图 classification completed.\n",
      "完成时间: 2024-10-25 13:56:33.485396\n",
      "Step 2: 筛选白底图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving images from D://code//data//Lv2期结论//男鞋_from_0501\\6912\\grounding_output: 100%|██████████| 1156/1156 [05:07<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成时间: 2024-10-25 14:01:40.752562\n",
      "Step 3: 筛选功能卖点图\n",
      "Step 4: 归类图片到 scene\n",
      "Image moving completed.\n",
      "完成时间: 2024-10-25 14:07:44.823355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   5%|▌         | 19/364 [02:24<43:52,  7.63s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image classification completed.\n",
      "okkk\n",
      "当前系统时间是: 2024-10-25 14:10:09.812357\n",
      "当前系统时间是: 2024-10-25 14:10:09.812357\n",
      "当前系统时间是: 2024-10-25 14:10:09.812357\n",
      "Step 1: 筛选价促卖点图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 1080/1080 [29:13<00:00,  1.62s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卖点图 classification completed.\n",
      "完成时间: 2024-10-25 14:39:23.615116\n",
      "Step 2: 筛选白底图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving images from D://code//data//Lv2期结论//男鞋_from_0501\\6913\\grounding_output: 100%|██████████| 871/871 [03:57<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成时间: 2024-10-25 14:43:20.774983\n",
      "Step 3: 筛选功能卖点图\n",
      "Step 4: 归类图片到 scene\n",
      "Image moving completed.\n",
      "完成时间: 2024-10-25 15:00:25.032667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  15%|█▌        | 32/210 [04:04<22:37,  7.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image classification completed.\n",
      "okkk\n",
      "当前系统时间是: 2024-10-25 15:04:29.138892\n",
      "当前系统时间是: 2024-10-25 15:04:29.138892\n",
      "当前系统时间是: 2024-10-25 15:04:29.138892\n",
      "Step 1: 筛选价促卖点图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 7/7 [00:14<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卖点图 classification completed.\n",
      "完成时间: 2024-10-25 15:04:43.964532\n",
      "Step 2: 筛选白底图\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving images from D://code//data//Lv2期结论//男鞋_from_0501\\9783\\grounding_output: 100%|██████████| 7/7 [00:01<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成时间: 2024-10-25 15:04:45.905748\n",
      "Step 3: 筛选功能卖点图\n",
      "Step 4: 归类图片到 scene\n",
      "Image moving completed.\n",
      "完成时间: 2024-10-25 15:04:49.633090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/2 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image classification completed.\n",
      "okkk\n",
      "当前系统时间是: 2024-10-25 15:04:52.229769\n",
      "当前系统时间是: 2024-10-25 15:04:52.229769\n",
      "当前系统时间是: 2024-10-25 15:04:52.229769\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from paddleocr import PaddleOCR\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "z = '男鞋_from_0501'\n",
    "\n",
    "\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "\n",
    "def process_folder(root_folder):\n",
    "    # 初始化 PaddleOCR\n",
    "    ocr = PaddleOCR(use_angle_cls=True, lang=\"ch\", show_log=False)\n",
    "\n",
    "    # 遍历根文件夹下的所有子文件夹\n",
    "    for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "        if os.path.basename(dirpath) == 'grounding_output':\n",
    "            price_folder = os.path.join(dirpath, 'price')\n",
    "            txt_folder = os.path.join(dirpath, 'txt')\n",
    "            scene_folder = os.path.join(dirpath, 'scene')\n",
    "            white_folder = os.path.join(dirpath, 'white')\n",
    "\n",
    "            # 如果文件夹不存在，则创建\n",
    "            for folder in [price_folder, txt_folder, scene_folder, white_folder]:\n",
    "                if not os.path.exists(folder):\n",
    "                    os.makedirs(folder)\n",
    "\n",
    "            '''\n",
    "            step1 - 筛选价促卖点图\n",
    "            '''\n",
    "            print('Step 1: 筛选价促卖点图')\n",
    "\n",
    "            image_files = [os.path.join(dirpath, filename) for filename in os.listdir(dirpath) if filename.endswith(('.jpg', '.png'))]\n",
    "\n",
    "            # 使用 tqdm 创建进度条\n",
    "            with tqdm(total=len(image_files), desc=\"Processing images\") as pbar:\n",
    "                # 遍历源文件夹中的所有图片文件\n",
    "                for filename in image_files:\n",
    "                    img_path = os.path.join(dirpath, filename)\n",
    "\n",
    "                    # 使用 PaddleOCR 进行文字识别\n",
    "                    result = ocr.ocr(img_path, cls=True)\n",
    "\n",
    "                    if not result:\n",
    "                        # 如果识别结果为空,则跳过这张图片,不进行移动操作\n",
    "                        pbar.write(f\"Image '{filename}' skipped due to empty OCR result.\")\n",
    "                        pbar.update(1)\n",
    "                        continue\n",
    "\n",
    "                    data_list = result[0]\n",
    "\n",
    "                    # 检查识别结果是否有关键词\n",
    "                    contains_keyword = False\n",
    "\n",
    "                    if data_list:\n",
    "                        # 定义关键词列表\n",
    "                        keywords = ['满', '减', '折', '到手价', '送', '免息', '活动价', '包邮价', '参考价',\n",
    "                                    r'.*满.*减.*', r'.*满.*-.*', r'.*满.*赠.*', r'.*满.*送.*', r'.*价.*',\n",
    "                                    '券', '优惠', '用券', '领券', '券', '送', '低至', '立减', '直降', '免息',\n",
    "                                    '¥', '夫', '￥']\n",
    "\n",
    "                        # 遍历识别结果中的文本\n",
    "                        for data in data_list:\n",
    "                            text = data[1][0]  # 获取文本内容\n",
    "                            # 检查当前文本是否包含关键词\n",
    "                            if any(keyword in text for keyword in keywords):\n",
    "                                contains_keyword = True\n",
    "                                break\n",
    "\n",
    "                    # 根据检查结果移动文件\n",
    "                    if contains_keyword:\n",
    "                        try:\n",
    "                            shutil.move(img_path, price_folder)\n",
    "                            # pbar.write(f\"Image '{filename}' moved to price_folder.\")\n",
    "                        except Exception as e:\n",
    "                            pbar.write(f\"Failed to move image '{filename}': {e}\")\n",
    "                            continue\n",
    "                    # else:\n",
    "                    #     # 如果不包含关键词，移动到其他文件夹\n",
    "                    #     # 你可以根据需要修改这里的逻辑\n",
    "                    #     try:\n",
    "                    #         shutil.move(img_path, txt_folder)\n",
    "                    #         pbar.write(f\"Image '{filename}' moved to scene_folder.\")\n",
    "                    #     except Exception as e:\n",
    "                    #         pbar.write(f\"Failed to move image '{filename}': {e}\")\n",
    "\n",
    "                    # 重置 contains_keyword 变量\n",
    "                    contains_keyword = False\n",
    "\n",
    "                    # 更新进度条\n",
    "                    pbar.update(1)\n",
    "\n",
    "            print(\"卖点图 classification completed.\")\n",
    "\n",
    "            # 获取当前时间\n",
    "            current_time = datetime.now()\n",
    "\n",
    "            # 格式化输出当前时间\n",
    "            print(\"完成时间:\", current_time)\n",
    "\n",
    "            '''\n",
    "            step2 - 筛选白底图\n",
    "            '''\n",
    "\n",
    "            print('Step 2: 筛选白底图')\n",
    "\n",
    "            def move_images_with_white_pixels(base_path, white_folder, threshold=0.40):\n",
    "                # 获取源文件夹中的图片文件列表\n",
    "                image_files = [filename for filename in os.listdir(base_path) if filename.endswith(('.jpg', '.png'))]\n",
    "\n",
    "                # 使用 tqdm 创建进度条\n",
    "                with tqdm(total=len(image_files), desc=f\"Moving images from {base_path}\") as pbar:\n",
    "                    # 遍历源文件夹中的所有图片文件\n",
    "                    for filename in image_files:\n",
    "                        img_path = os.path.join(base_path, filename)\n",
    "\n",
    "                        # 打开图片并获取像素信息\n",
    "                        with Image.open(img_path) as img:\n",
    "                            # 确认图片是 RGB 模式\n",
    "                            if img.mode!= 'RGB':\n",
    "                                img = img.convert('RGB')\n",
    "                            # 获取图片的宽度和高度\n",
    "                            width, height = img.size\n",
    "\n",
    "                            # 统计白色像素点的数量\n",
    "                            white_pixels = 0\n",
    "                            for x in range(width):\n",
    "                                for y in range(height):\n",
    "                                    # 获取像素点的 RGB 值\n",
    "                                    pixel_value = img.getpixel((x, y))\n",
    "                                    # 如果是 RGB 图像，解包为三个值，否则为四个值\n",
    "                                    if len(pixel_value) == 3:\n",
    "                                        r, g, b = pixel_value\n",
    "                                    else:  # 处理带有透明度的图像\n",
    "                                        r, g, b, a = pixel_value\n",
    "                                    # 如果 RGB 值都大于 230，则认为是白色像素点\n",
    "                                    if r > 230 and g > 230 and b > 230:\n",
    "                                        white_pixels += 1\n",
    "\n",
    "                            # 计算白色像素点占比\n",
    "                            white_ratio = white_pixels / (width * height)\n",
    "\n",
    "                            # 如果白色像素点占比超过阈值，则将图片移动到目标文件夹\n",
    "                            if white_ratio > threshold:\n",
    "                                target_path = os.path.join(white_folder, filename)\n",
    "                                try:\n",
    "                                    shutil.move(img_path, white_folder)\n",
    "                                    # pbar.write(f\"Image '{filename}' moved to white folder.\")\n",
    "                                except Exception as e:\n",
    "                                    pbar.write(f\"Error moving image '{filename}': {e}\")\n",
    "                                    continue\n",
    "\n",
    "                        # 更新进度条\n",
    "                        pbar.update(1)\n",
    "\n",
    "            # 调用函数，将白色像素点占比超过 30%的图片从源文件夹列表中移动到目标文件夹\n",
    "            move_images_with_white_pixels(dirpath, white_folder, threshold=0.40)\n",
    "\n",
    "            # 获取当前时间\n",
    "            current_time = datetime.now()\n",
    "\n",
    "            # 格式化输出当前时间\n",
    "            print(\"完成时间:\", current_time)\n",
    "\n",
    "            '''\n",
    "            step3 - 筛选功能卖点图\n",
    "            '''\n",
    "\n",
    "            print('Step 3: 筛选功能卖点图')\n",
    "\n",
    "            image_files = [filename for filename in os.listdir(dirpath) if filename.endswith(('.jpg', '.png'))]\n",
    "            for filename in image_files:\n",
    "\n",
    "                img_path = os.path.join(dirpath, filename)\n",
    "                # print(f\"Processing image: {img_path}\")\n",
    "\n",
    "                img = Image.open(img_path)\n",
    "                width, height = img.size\n",
    "\n",
    "                # 读取图片下部分 5/6\n",
    "                cropped_img = img.crop((0, height // 6, width, height))\n",
    "\n",
    "                # 将 PIL 图像对象转换为 numpy 数组\n",
    "                img_np = np.array(cropped_img)\n",
    "\n",
    "                # OCR 处理\n",
    "                result = ocr.ocr(img_np, cls=True)\n",
    "\n",
    "                if result is None:\n",
    "                    continue\n",
    "\n",
    "                rectangles_with_text = result[0]\n",
    "\n",
    "                if rectangles_with_text is None:\n",
    "                    continue\n",
    "\n",
    "                line_count = len(rectangles_with_text)\n",
    "\n",
    "                # 如果文本行数大于等于 3, 将图片移动到目标文件夹\n",
    "                if line_count >= 2:\n",
    "                    target_path = os.path.join(txt_folder, filename)\n",
    "                    shutil.move(img_path, txt_folder)\n",
    "                    # print(f\"'{filename}' moved to txt folder.\")\n",
    "\n",
    "                else:\n",
    "                    # print(f\"'{filename}' remains in source folder.\")\n",
    "                    continue\n",
    "\n",
    "            '''\n",
    "            step4 - 将剩余图片归类到 scene\n",
    "            '''\n",
    "\n",
    "            print('Step 4: 归类图片到 scene')\n",
    "\n",
    "            # 检查目标文件夹是否存在，如果不存在则创建\n",
    "            if not os.path.exists(scene_folder):\n",
    "                os.makedirs(scene_folder)\n",
    "\n",
    "            # 获取源文件夹中的所有图片文件列表\n",
    "            image_files = [filename for filename in os.listdir(dirpath) if filename.endswith(('.jpg', '.png'))]\n",
    "\n",
    "            # 移动图片到 txt_folder\n",
    "            for filename in image_files:\n",
    "                img_path = os.path.join(dirpath, filename)\n",
    "                target_path = os.path.join(scene_folder, filename)\n",
    "                shutil.move(img_path, scene_folder)\n",
    "                # print(f\"Image '{filename}' moved to scene_folder.\")\n",
    "\n",
    "            print(\"Image moving completed.\")\n",
    "\n",
    "            # 获取当前时间\n",
    "            current_time = datetime.now()\n",
    "\n",
    "            # 格式化输出当前时间\n",
    "            print(\"完成时间:\", current_time)\n",
    "\n",
    "            '''\n",
    "            step5 - 将 white 中有文本的图片移到 txt_folder\n",
    "            '''\n",
    "\n",
    "            # 获取源文件夹中的所有图片文件列表\n",
    "            image_files = [filename for filename in os.listdir(white_folder) if filename.endswith(('.jpg', '.png'))]\n",
    "\n",
    "            # 使用 tqdm 创建进度条\n",
    "            with tqdm(total=len(image_files), desc=\"Processing images\") as pbar:\n",
    "\n",
    "                # 遍历源文件夹中的所有图片文件\n",
    "                for filename in image_files:\n",
    "                    img_path = os.path.join(white_folder, filename)\n",
    "\n",
    "                    img = Image.open(img_path)\n",
    "                    width, height = img.size\n",
    "\n",
    "                    # 读取图片下部分 3/4\n",
    "                    cropped_img = img.crop((0, height // 6, width, height))\n",
    "\n",
    "                    # 将 PIL 图像对象转换为 numpy 数组\n",
    "                    img_np = np.array(cropped_img)\n",
    "\n",
    "                    # OCR 处理\n",
    "                    result = ocr.ocr(img_np, cls=True)\n",
    "\n",
    "                    if result is None:\n",
    "                        continue\n",
    "\n",
    "                    rectangles_with_text = result[0]\n",
    "\n",
    "                    if rectangles_with_text is None:\n",
    "                        continue\n",
    "\n",
    "                    # 统计文本框高度大于 30 像素的行数\n",
    "                    lines_above_30_count = 0\n",
    "                    for rectangle in rectangles_with_text:\n",
    "                        # 计算文本框的高度和宽度\n",
    "                        points = rectangle[0]\n",
    "                        x_A, y_A = points[0]\n",
    "\n",
    "                        # 计算 A 点到 BCD 的距离\n",
    "                        distances = []\n",
    "                        for point in points[1:]:\n",
    "                            x_B, y_B = point\n",
    "                            distance = math.sqrt((x_B - x_A) ** 2 + (y_B - y_A) ** 2)\n",
    "                            distances.append(distance)\n",
    "\n",
    "                        # 获取最短的距离作为文本框的大小\n",
    "                        text_size = min(distances)\n",
    "\n",
    "                        # 统计高度大于 x 像素的行数\n",
    "                        if text_size > 30:\n",
    "                            lines_above_30_count += 1\n",
    "\n",
    "                    # 如果大于 30 像素的行数大于等于 2，将图片移动到目标文件夹\n",
    "                    if lines_above_30_count >= 2:\n",
    "                        # 如果识别结果不为空且行数小于等于 3，则将图片复制到 txt_folder\n",
    "                        target_path = os.path.join(txt_folder, filename)\n",
    "                        shutil.move(img_path, target_path)\n",
    "                        # pbar.write(f\"Image '{filename}' copied to txt_folder.\")\n",
    "                    else:\n",
    "                        # pbar.write(f\"Image '{filename}' remains in source folder.\")\n",
    "                        continue\n",
    "\n",
    "                    # 更新进度条\n",
    "                    pbar.update(1)\n",
    "\n",
    "            print(\"Image classification completed.\")\n",
    "\n",
    "            print('okkk')\n",
    "\n",
    "root_folder = f\"D://code//data//Lv2期结论//{z}\"\n",
    "process_folder(root_folder)\n",
    "\n",
    "\n",
    "# 获取当前时间\n",
    "current_time = datetime.now()\n",
    "\n",
    "# 打印当前时间\n",
    "print(\"当前系统时间是:\", current_time)\n",
    "print(\"当前系统时间是:\", current_time)\n",
    "print(\"当前系统时间是:\", current_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step2.1 - 对四分类的数据总结\n",
    "### 针对整体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "统计结果 for 12066:\n",
      "  scene: 图片数量 = 3, UV = 119, Click UV = 9, CTR = 0.0756\n",
      "\n",
      "统计结果 for 6908:\n",
      "  price: 图片数量 = 462, UV = 1997399, Click UV = 75119, CTR = 0.0376\n",
      "  txt: 图片数量 = 120, UV = 2777440, Click UV = 90451, CTR = 0.0326\n",
      "  scene: 图片数量 = 721, UV = 14113428, Click UV = 461185, CTR = 0.0327\n",
      "  white: 图片数量 = 246, UV = 2132073, Click UV = 76381, CTR = 0.0358\n",
      "\n",
      "统计结果 for 6909:\n",
      "  price: 图片数量 = 446, UV = 787151, Click UV = 28230, CTR = 0.0359\n",
      "  txt: 图片数量 = 275, UV = 2535197, Click UV = 100304, CTR = 0.0396\n",
      "  scene: 图片数量 = 556, UV = 6398186, Click UV = 275823, CTR = 0.0431\n",
      "  white: 图片数量 = 263, UV = 1562568, Click UV = 60597, CTR = 0.0388\n",
      "\n",
      "统计结果 for 6910:\n",
      "  price: 图片数量 = 63, UV = 50103, Click UV = 2934, CTR = 0.0586\n",
      "  txt: 图片数量 = 169, UV = 844799, Click UV = 27781, CTR = 0.0329\n",
      "  scene: 图片数量 = 242, UV = 1738848, Click UV = 74195, CTR = 0.0427\n",
      "  white: 图片数量 = 261, UV = 497952, Click UV = 20120, CTR = 0.0404\n",
      "\n",
      "统计结果 for 6911:\n",
      "  price: 图片数量 = 50, UV = 1135608, Click UV = 54777, CTR = 0.0482\n",
      "  txt: 图片数量 = 299, UV = 4190983, Click UV = 156542, CTR = 0.0374\n",
      "  scene: 图片数量 = 360, UV = 10489691, Click UV = 398049, CTR = 0.0379\n",
      "  white: 图片数量 = 185, UV = 3788141, Click UV = 158589, CTR = 0.0419\n",
      "\n",
      "统计结果 for 6912:\n",
      "  price: 图片数量 = 755, UV = 380245, Click UV = 16481, CTR = 0.0433\n",
      "  txt: 图片数量 = 88, UV = 242284, Click UV = 11687, CTR = 0.0482\n",
      "  scene: 图片数量 = 723, UV = 1168290, Click UV = 49293, CTR = 0.0422\n",
      "  white: 图片数量 = 345, UV = 371182, Click UV = 15245, CTR = 0.0411\n",
      "\n",
      "统计结果 for 6913:\n",
      "  price: 图片数量 = 209, UV = 966789, Click UV = 52207, CTR = 0.0540\n",
      "  txt: 图片数量 = 471, UV = 1380509, Click UV = 78914, CTR = 0.0572\n",
      "  scene: 图片数量 = 222, UV = 919926, Click UV = 42097, CTR = 0.0458\n",
      "  white: 图片数量 = 178, UV = 389416, Click UV = 17690, CTR = 0.0454\n",
      "\n",
      "统计结果 for 9783:\n",
      "  scene: 图片数量 = 5, UV = 1577, Click UV = 69, CTR = 0.0438\n",
      "  white: 图片数量 = 2, UV = 54, Click UV = 4, CTR = 0.0741\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\12066_brand_all_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\6908_brand_all_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\6909_brand_all_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\6910_brand_all_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\6911_brand_all_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\6912_brand_all_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\6913_brand_all_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\9783_brand_all_url_1_chart.png\n",
      "统计结果已保存至Excel文件: D://code//data//Lv2期结论//男鞋_from_0501\\url_1\\brand_all_url_1_chart.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "\n",
    "# 所有的通用变量都放在这里,方便管理\n",
    "x_list = ['6908','6909','6910','6911','6912','6913','9783','12066']\n",
    "y_list = ['txt', 'price']\n",
    "path = 'Lv2期结论'\n",
    "z = '男鞋_from_0501'\n",
    "\n",
    "# 定义基础路径和CSV文件路径\n",
    "base_path = f'D://code//data//Lv2期结论//{z}'\n",
    "csv_file_path = f'D://code//data//Lv2期结论//{z}//{z}.csv'\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "def extract_matching_part(img_url):\n",
    "    if pd.isna(img_url):\n",
    "        return None\n",
    "    img_url = img_url.split('?')[0]\n",
    "    img_url = os.path.splitext(img_url)[0]\n",
    "    parts = img_url.split('/')\n",
    "    if len(parts) >= 2:\n",
    "        return f\"{parts[-2]}_{parts[-1]}\"\n",
    "    return None\n",
    "\n",
    "df['matching_part'] = df['img_url'].apply(extract_matching_part)\n",
    "\n",
    "def process_grounding_folder(grounding_path):\n",
    "    folder_stats = {\n",
    "        'price': {'count': 0, 'uv': 0, 'click_uv': 0},\n",
    "        'txt': {'count': 0, 'uv': 0, 'click_uv': 0},\n",
    "        'scene': {'count': 0, 'uv': 0, 'click_uv': 0},\n",
    "        'white': {'count': 0, 'uv': 0, 'click_uv': 0}\n",
    "    }\n",
    "\n",
    "    for folder_name in ['price', 'txt', 'scene', 'white']:\n",
    "        folder_path = os.path.join(grounding_path, folder_name)\n",
    "        if os.path.exists(folder_path):\n",
    "            for filename in os.listdir(folder_path):\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "                    filename_without_ext = os.path.splitext(filename)[0]\n",
    "                    filtered_df = df[df['matching_part'] == filename_without_ext]\n",
    "                    if not filtered_df.empty:\n",
    "                        folder_stats[folder_name]['count'] += 1\n",
    "                        folder_stats[folder_name]['uv'] += filtered_df['uv'].sum()\n",
    "                        folder_stats[folder_name]['click_uv'] += filtered_df['click_uv'].sum()\n",
    "\n",
    "    # 计算每个文件夹的CTR\n",
    "    for folder in folder_stats:\n",
    "        if folder_stats[folder]['uv'] > 0:\n",
    "            folder_stats[folder]['ctr'] = folder_stats[folder]['click_uv'] / folder_stats[folder]['uv']\n",
    "        else:\n",
    "            folder_stats[folder]['ctr'] = 0\n",
    "\n",
    "    return folder_stats\n",
    "\n",
    "all_stats = {}\n",
    "\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    if 'grounding_output' in dirs:\n",
    "        grounding_path = os.path.join(root, 'grounding_output')\n",
    "        folder_name = os.path.basename(root)\n",
    "        stats = process_grounding_folder(grounding_path)\n",
    "        all_stats[folder_name] = stats\n",
    "\n",
    "# 创建一个Excel工作簿来保存结果\n",
    "workbook = openpyxl.Workbook()\n",
    "sheet = workbook.active\n",
    "sheet.title = \"Image Distribution Stats\"\n",
    "\n",
    "# 写入表头\n",
    "headers = [\"Folder\", \"Subfolder\", \"Count\", \"UV\", \"Click UV\", \"CTR\", \"Brand\"]\n",
    "for col, header in enumerate(headers, start=1):\n",
    "    sheet.cell(row=1, column=col, value=header)\n",
    "\n",
    "row = 2  # 从第二行开始写入数据\n",
    "\n",
    "# 检查并创建url_1文件夹\n",
    "output_folder = os.path.join(base_path, 'url_1')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 输出统计结果\n",
    "for folder, stats in all_stats.items():\n",
    "    print(f\"\\n统计结果 for {folder}:\")\n",
    "    for subfolder, data in stats.items():\n",
    "        if data['count'] > 0:\n",
    "            ctr = data['click_uv'] / data['uv'] if data['uv'] > 0 else 0\n",
    "            print(f\"  {subfolder}: 图片数量 = {data['count']}, UV = {data['uv']}, Click UV = {data['click_uv']}, CTR = {ctr:.4f}\")\n",
    "\n",
    "# 定义颜色映射\n",
    "color_map = {\n",
    "    'price': '#FF6B6B',  # 柔和的红色\n",
    "    'txt': '#4ECDC4',    # 青绿色\n",
    "    'scene': '#7986CB',  # 淡紫色\n",
    "    'white': '#FFD93D'   # 明亮的黄色\n",
    "}\n",
    "\n",
    "# 绘制每个grounding_output文件夹的饼图并保存数据\n",
    "for folder, stats in all_stats.items():\n",
    "    counts = [data['count'] for data in stats.values() if data['count'] > 0]\n",
    "    labels = [subfolder for subfolder, data in stats.items() if data['count'] > 0]\n",
    "    ctrs = [data['ctr'] for data in stats.values() if data['count'] > 0]\n",
    "    colors = [color_map.get(label, 'gray') for label in labels]  # 使用颜色映射，如果没有指定则默认为灰色\n",
    "    \n",
    "    if counts:  # 只有当有数据时才绘图\n",
    "        plt.figure(figsize=(12, 9))\n",
    "        wedges, texts, autotexts = plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "        \n",
    "        # 添加数量和CTR标签\n",
    "        for i, (autotext, ctr) in enumerate(zip(autotexts, ctrs)):\n",
    "            autotext.set_text(f'{autotext.get_text()}\\n({counts[i]})\\nCTR: {ctr:.4f}')\n",
    "        \n",
    "        plt.title(f\"Image Distribution in {folder}\")\n",
    "        plt.axis('equal')\n",
    "\n",
    "        # 添加图例\n",
    "        plt.legend(wedges, [f\"{label} ({count}, CTR: {ctr:.4f})\" for label, count, ctr in zip(labels, counts, ctrs)],\n",
    "                    title=\"Categories\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "        \n",
    "        output_chart_path = os.path.join(output_folder, f'{folder}_brand_all_url_1_chart.png')\n",
    "        plt.savefig(output_chart_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"饼图已保存至: {output_chart_path}\")\n",
    "\n",
    "        # 写入数据到Excel, 添加品牌列 \"brand\" 的值为 \"all\"\n",
    "        for subfolder, data in stats.items():\n",
    "            if data['count'] > 0:\n",
    "                sheet.cell(row=row, column=1, value=folder)\n",
    "                sheet.cell(row=row, column=2, value=subfolder)\n",
    "                sheet.cell(row=row, column=3, value=data['count'])\n",
    "                sheet.cell(row=row, column=4, value=data['uv'])\n",
    "                sheet.cell(row=row, column=5, value=data['click_uv'])\n",
    "                sheet.cell(row=row, column=6, value=data['ctr'])\n",
    "                sheet.cell(row=row, column=7, value=\"all\")  # 添加品牌列，值为 \"all\"\n",
    "                row += 1\n",
    "\n",
    "# 保存Excel文件\n",
    "excel_output_path = os.path.join(output_folder, f'brand_all_url_1_chart.xlsx')\n",
    "workbook.save(excel_output_path)\n",
    "print(f\"统计结果已保存至Excel文件: {excel_output_path}\")\n",
    "\n",
    "import datetime\n",
    "current_time = datetime.datetime.now()\n",
    "formatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"完成时间: {formatted_time}\")\n",
    "print(f\"完成时间: {formatted_time}\")\n",
    "print(f\"完成时间: {formatted_time}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step2.2 - 对四分类的数据总结\n",
    "### 针对brand进行了分成的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heyunshen\\AppData\\Local\\Temp\\ipykernel_31720\\1564597199.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['matching_part'] = filtered_df['img_url'].apply(extract_matching_part)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6908_brand_1.0_2.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6909_brand_1.0_2.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6910_brand_1.0_2.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6911_brand_1.0_2.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6912_brand_1.0_2.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6913_brand_1.0_2.0_url_1_chart.png\n",
      "统计结果已保存至Excel文件: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//brand_1.0_2.0_url_1_chart.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heyunshen\\AppData\\Local\\Temp\\ipykernel_31720\\1564597199.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['matching_part'] = filtered_df['img_url'].apply(extract_matching_part)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6908_brand_3.0_4.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6909_brand_3.0_4.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6910_brand_3.0_4.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6911_brand_3.0_4.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6912_brand_3.0_4.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6913_brand_3.0_4.0_url_1_chart.png\n",
      "统计结果已保存至Excel文件: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//brand_3.0_4.0_url_1_chart.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heyunshen\\AppData\\Local\\Temp\\ipykernel_31720\\1564597199.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['matching_part'] = filtered_df['img_url'].apply(extract_matching_part)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//12066_brand_5.0_6.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6908_brand_5.0_6.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6909_brand_5.0_6.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6910_brand_5.0_6.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6911_brand_5.0_6.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6912_brand_5.0_6.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//6913_brand_5.0_6.0_url_1_chart.png\n",
      "饼图已保存至: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//9783_brand_5.0_6.0_url_1_chart.png\n",
      "统计结果已保存至Excel文件: D://code//data//Lv2期结论//男鞋_from_0501\\url_1//brand_5.0_6.0_url_1_chart.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "\n",
    "# 定义基础路径和CSV文件路径\n",
    "# z = '男士春夏下装_from_0501'\n",
    "base_path = f'D://code//data//Lv2期结论//{z}'\n",
    "csv_file_path = f'D://code//data//Lv2期结论//{z}//{z}.csv'\n",
    "brand_path = f'D://code//data//Lv2期结论//{z}//男鞋品牌分层.xlsx'\n",
    "\n",
    "# filter_layer_cases = [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]\n",
    "filter_layer_cases = [[1.0, 2.0],[3.0, 4.0], [5.0, 6.0]]\n",
    "\n",
    "\n",
    "for filter_layers in filter_layer_cases:\n",
    "    # 格式化 filter_layers\n",
    "    filter_layers_str = \"_\".join(map(str, filter_layers))\n",
    "\n",
    "    # 读取CSV文件和品牌分类文件\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df_brand = pd.read_excel(brand_path)\n",
    "\n",
    "    # 合并品牌信息\n",
    "    df = pd.merge(df, df_brand, on='main_brand_code', how='left')\n",
    "\n",
    "    # 筛选数据\n",
    "    filtered_df = df[df['最终分层'].isin(filter_layers)]\n",
    "\n",
    "    def extract_matching_part(img_url):\n",
    "        if pd.isna(img_url):\n",
    "            return None\n",
    "        img_url = img_url.split('?')[0]\n",
    "        img_url = os.path.splitext(img_url)[0]\n",
    "        parts = img_url.split('/')\n",
    "        if len(parts) >= 2:\n",
    "            return f\"{parts[-2]}_{parts[-1]}\"\n",
    "        return None\n",
    "\n",
    "    filtered_df['matching_part'] = filtered_df['img_url'].apply(extract_matching_part)\n",
    "\n",
    "    def process_grounding_folder(grounding_path):\n",
    "        folder_stats = {\n",
    "            'price': {'count': 0, 'uv': 0, 'click_uv': 0},\n",
    "            'txt': {'count': 0, 'uv': 0, 'click_uv': 0},\n",
    "            'scene': {'count': 0, 'uv': 0, 'click_uv': 0},\n",
    "            'white': {'count': 0, 'uv': 0, 'click_uv': 0}\n",
    "        }\n",
    "\n",
    "        for folder_name in ['price', 'txt', 'scene', 'white']:\n",
    "            folder_path = os.path.join(grounding_path, folder_name)\n",
    "            if os.path.exists(folder_path):\n",
    "                for filename in os.listdir(folder_path):\n",
    "                    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "                        filename_without_ext = os.path.splitext(filename)[0]\n",
    "                        folder_filtered_df = filtered_df[filtered_df['matching_part'] == filename_without_ext]\n",
    "                        if not folder_filtered_df.empty:\n",
    "                            folder_stats[folder_name]['count'] += 1\n",
    "                            folder_stats[folder_name]['uv'] += folder_filtered_df['uv'].sum()\n",
    "                            folder_stats[folder_name]['click_uv'] += folder_filtered_df['click_uv'].sum()\n",
    "\n",
    "        # 计算每个文件夹的CTR\n",
    "        for folder in folder_stats:\n",
    "            if folder_stats[folder]['uv'] > 0:\n",
    "                folder_stats[folder]['ctr'] = folder_stats[folder]['click_uv'] / folder_stats[folder]['uv']\n",
    "            else:\n",
    "                folder_stats[folder]['ctr'] = 0\n",
    "\n",
    "        return folder_stats\n",
    "\n",
    "    all_stats = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        if 'grounding_output' in dirs:\n",
    "            grounding_path = os.path.join(root, 'grounding_output')\n",
    "            folder_name = os.path.basename(root)\n",
    "            stats = process_grounding_folder(grounding_path)\n",
    "            all_stats[folder_name] = stats\n",
    "\n",
    "    # 定义颜色映射\n",
    "    color_map = {\n",
    "        'price': '#FF6B6B',  # 柔和的红色\n",
    "        'txt': '#4ECDC4',    # 青绿色\n",
    "        'scene': '#7986CB',  # 淡紫色\n",
    "        'white': '#FFD93D'   # 明亮的黄色\n",
    "    }\n",
    "\n",
    "    # 绘制饼图\n",
    "    for folder, stats in all_stats.items():\n",
    "        counts = [data['count'] for data in stats.values() if data['count'] > 0]\n",
    "        labels = [subfolder for subfolder, data in stats.items() if data['count'] > 0]\n",
    "        ctrs = [data['ctr'] for data in stats.values() if data['count'] > 0]\n",
    "        colors = [color_map.get(label, 'gray') for label in labels]  # 使用颜色映射，如果没有指定则默认为灰色\n",
    "        \n",
    "        if counts:  # 只有当有数据时才绘图\n",
    "            plt.figure(figsize=(12, 9))\n",
    "            wedges, texts, autotexts = plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "            \n",
    "            # 添加数量和CTR标签\n",
    "            for i, (autotext, ctr) in enumerate(zip(autotexts, ctrs)):\n",
    "                autotext.set_text(f'{autotext.get_text()}\\n({counts[i]})\\nCTR: {ctr:.4f}')\n",
    "            \n",
    "            plt.title(f\"Image Distribution in {folder} ({filter_layers_str})\")\n",
    "            plt.axis('equal')\n",
    "            \n",
    "            # 添加图例\n",
    "            plt.legend(wedges, [f\"{label} ({count}, CTR: {ctr:.4f})\" for label, count, ctr in zip(labels, counts, ctrs)],\n",
    "                       title=\"Categories\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "            \n",
    "            output_chart_path = os.path.join(base_path, f'url_1//{folder}_brand_{filter_layers_str}_url_1_chart.png')\n",
    "            plt.savefig(output_chart_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"饼图已保存至: {output_chart_path}\")\n",
    "\n",
    "    # 创建一个Excel工作簿来保存结果\n",
    "    workbook = openpyxl.Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = f\"Stats ({filter_layers_str})\"\n",
    "\n",
    "    # 写入表头\n",
    "    headers = [\"Folder\", \"Subfolder\", \"Count\", \"UV\", \"Click UV\", \"CTR\", \"Brand\"]\n",
    "    for col, header in enumerate(headers, start=1):\n",
    "        sheet.cell(row=1, column=col, value=header)\n",
    "\n",
    "    row = 2  # 从第二行开始写入数据\n",
    "\n",
    "    # 写入统计数据\n",
    "    for folder, stats in all_stats.items():\n",
    "        for subfolder, data in stats.items():\n",
    "            if data['count'] > 0:\n",
    "                sheet.cell(row=row, column=1, value=folder)\n",
    "                sheet.cell(row=row, column=2, value=subfolder)\n",
    "                sheet.cell(row=row, column=3, value=data['count'])\n",
    "                sheet.cell(row=row, column=4, value=data['uv'])\n",
    "                sheet.cell(row=row, column=5, value=data['click_uv'])\n",
    "                sheet.cell(row=row, column=6, value=data['ctr'])\n",
    "                sheet.cell(row=row, column=7, value=filter_layers_str)  # 添加品牌列，值为格式化后的筛选条件\n",
    "                row += 1\n",
    "\n",
    "    # 保存Excel文件\n",
    "    output_folder = os.path.join(base_path)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    excel_output_path = os.path.join(output_folder, f'url_1//brand_{filter_layers_str}_url_1_chart.xlsx')\n",
    "    workbook.save(excel_output_path)\n",
    "    print(f\"统计结果已保存至Excel文件: {excel_output_path}\")\n",
    "\n",
    "import datetime\n",
    "current_time = datetime.datetime.now()\n",
    "formatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"完成时间: {formatted_time}\")\n",
    "print(f\"完成时间: {formatted_time}\")\n",
    "print(f\"完成时间: {formatted_time}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将分类结果统计为excel文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 指定要拼接的Excel文件路径列表\n",
    "excel_file_paths = [\n",
    "    f\"D://code//data//Lv2期结论//{z}//url_1//brand_all_url_1_chart.xlsx\",\n",
    "    f\"D://code//data//Lv2期结论//{z}//url_1//brand_1.0_2.0_3.0_url_1_chart.xlsx\",\n",
    "    f\"D://code//data//Lv2期结论//{z}//url_1//brand_1.0_2.0_3.0_url_1_chart.xlsx\",\n",
    "    f\"D://code//data//Lv2期结论//{z}//url_1//brand_4.0_5.0_6.0_url_1_chart.xlsx\"\n",
    "]\n",
    "\n",
    "# 用于存储读取的每个Excel文件的数据框\n",
    "dataframes = []\n",
    "\n",
    "# 逐个读取指定的Excel文件并添加到dataframes列表中\n",
    "for file_path in excel_file_paths:\n",
    "    df = pd.read_excel(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# 将所有数据框上下拼接在一起\n",
    "merged_df = pd.concat(dataframes, axis=0, ignore_index=True)\n",
    "\n",
    "# 可以根据需要将拼接后的结果保存为新的Excel文件\n",
    "merged_df.to_excel(f\"D://code//data//Lv2期结论//{z}//url_1//all_url_1_chart.xlsx\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# # 存储图片信息的列表\n",
    "# image_info = []\n",
    "\n",
    "\n",
    "# # x = '京喜_from_0501'\n",
    "\n",
    "\n",
    "# # 一级文件夹路径\n",
    "# root_folder = f'D://code//data//Lv2期结论//{x}//筛选'\n",
    "\n",
    "\n",
    "\n",
    "# # 遍历一级文件夹下的所有二级文件夹\n",
    "# for sub_folder in os.listdir(root_folder):\n",
    "#     if sub_folder.isdigit():  # 只处理数字命名的二级文件夹\n",
    "#         grounding_folder = os.path.join(root_folder, sub_folder, 'grounding_output')\n",
    "#         if os.path.exists(grounding_folder):\n",
    "#             for sub_sub_folder in ['price', 'txt', 'white', 'scene']:\n",
    "#                 sub_sub_folder_path = os.path.join(grounding_folder, sub_sub_folder)\n",
    "#                 if os.path.exists(sub_sub_folder_path):\n",
    "#                     for image_file in os.listdir(sub_sub_folder_path):\n",
    "#                         if \"txt_\" in image_file:\n",
    "#                             image_file = image_file.replace(\"txt_\", \"\")\n",
    "#                         elif \"price_\" in image_file:\n",
    "#                             image_file = image_file.replace(\"price_\", \"\")\n",
    "#                         image_info.append([image_file, sub_sub_folder, sub_folder])\n",
    "\n",
    "# # 创建DataFrame并保存为Excel\n",
    "# df = pd.DataFrame(image_info, columns=['图片名', '分类', 'cid3'])\n",
    "# # df.to_excel('D://code//data//Lv2期结论//京喜_from_0501//筛选//分类数据image_info.xlsx', index=False)\n",
    "\n",
    "# # 读取Excel文件\n",
    "# # data = pd.read_csv('D://code//data//Lv2期结论//京喜_from_0501//京喜数据_from_0501_筛选.csv')\n",
    "# # df2 = pd.read_csv('D://code//data//Lv2期结论//京喜_from_0501//京喜数据_from_0501_筛选.csv')\n",
    "\n",
    "# df2 = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # 按照img_url列进行聚合，并对指定列进行求和\n",
    "# aggregated_data = df2.groupby('img_url').agg({\n",
    "#     'uv':'sum',\n",
    "#     'click_uv':'sum',\n",
    "#     'gmv_cj':'sum',\n",
    "#     'sale_qtty_cj':'sum'\n",
    "# }).reset_index()\n",
    "\n",
    "# # 将原始数据中与聚合相关的列合并到聚合后的数据中\n",
    "# aggregated_data = pd.merge(aggregated_data, df2[['sku', 'img_url','img_type', 'bu_id', 'cid1', 'cid2', 'cid3', 'main_brand_code','shop_id']], on='img_url', how='left')\n",
    "\n",
    "# # 保存为新的Excel文件\n",
    "# # aggregated_data.to_excel('D://code//data//Lv2期结论//京喜_from_0501//url加总原始数据.xlsx', index=False)\n",
    "# # csv_file_path = 'D://code//data//Lv2期结论//京喜_from_0501//url加总原始数据.xlsx'\n",
    "# # df = pd.read_excel(csv_file_path)\n",
    "\n",
    "# def extract_matching_part(img_url):\n",
    "#     if pd.isna(img_url):\n",
    "#         return None\n",
    "#     img_url = img_url.split('?')[0]\n",
    "#     img_url = os.path.splitext(img_url)[0]\n",
    "#     parts = img_url.split('/')\n",
    "#     if len(parts) >= 2:\n",
    "#         return f\"{parts[-2]}_{parts[-1]}\"\n",
    "#     return None\n",
    "\n",
    "# aggregated_data['matching_part'] = aggregated_data['img_url'].apply(extract_matching_part)\n",
    "\n",
    "# # df_x = pd.read_excel('D://code//data//Lv2期结论//京喜_from_0501//筛选//分类数据image_info.xlsx')\n",
    "\n",
    "# # 确保列数据类型匹配（如果需要）\n",
    "# aggregated_data['matching_part'] = aggregated_data['matching_part'].astype(str)\n",
    "# df['图片名'] = df['图片名'].apply(lambda x: str(x).replace('.jpg', '') if isinstance(x, (str, bytes)) else x)\n",
    "\n",
    "# # 根据条件进行拼接\n",
    "# merged_df = pd.merge(aggregated_data, df, left_on='matching_part', right_on='图片名', how='right')\n",
    "# merged_df.to_excel(f'D://code//data//Lv2期结论//{x}//sku分类数据表.xlsx', index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
