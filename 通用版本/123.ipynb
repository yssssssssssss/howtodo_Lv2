{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m box_convert\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model, load_image, predict, annotate\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msegment_anything\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sam_model_registry, SamPredictor\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\n",
      "File \u001b[1;32md:\\code\\cv\\groundingdino\\groundingdino\\util\\inference.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m box_convert\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mT\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_model\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clean_state_dict\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mslconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SLConfig\n",
      "File \u001b[1;32md:\\code\\cv\\groundingdino\\groundingdino\\models\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Grounding DINO\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# url: https://github.com/IDEA-Research/GroundingDINO\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mGroundingDINO\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_groundingdino\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(args):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# we use register to maintain models from catdet6 on.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MODULE_BUILD_FUNCS\n",
      "File \u001b[1;32md:\\code\\cv\\groundingdino\\groundingdino\\models\\GroundingDINO\\__init__.py:15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Grounding DINO\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# url: https://github.com/IDEA-Research/GroundingDINO\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroundingdino\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_groundingdino\n",
      "File \u001b[1;32md:\\code\\cv\\groundingdino\\groundingdino\\models\\GroundingDINO\\groundingdino.py:41\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvl_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_positive_map_from_span\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MODULE_BUILD_FUNCS\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_backbone\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbertwarper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     43\u001b[0m     BertModelWarper,\n\u001b[0;32m     44\u001b[0m     generate_masks_with_special_tokens,\n\u001b[0;32m     45\u001b[0m     generate_masks_with_special_tokens_and_transfer_map,\n\u001b[0;32m     46\u001b[0m )\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_transformer\n",
      "File \u001b[1;32md:\\code\\cv\\groundingdino\\groundingdino\\models\\GroundingDINO\\backbone\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_backbone\n",
      "File \u001b[1;32md:\\code\\cv\\groundingdino\\groundingdino\\models\\GroundingDINO\\backbone\\backbone.py:30\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NestedTensor, clean_state_dict, is_main_process\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mposition_encoding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_position_encoding\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mswin_transformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_swin_transformer\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFrozenBatchNorm2d\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    BatchNorm2d where the batch statistics and the affine parameters are fixed.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    produce nans.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32md:\\code\\cv\\groundingdino\\groundingdino\\models\\GroundingDINO\\backbone\\swin_transformer.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcheckpoint\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DropPath, to_2tuple, trunc_normal_\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgroundingdino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NestedTensor\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMlp\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\lib\\site-packages\\timm\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_scriptable, is_exportable, set_scriptable, set_exportable\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_model, list_models, list_pretrained, is_model, list_modules, model_entrypoint, \\\n\u001b[0;32m      4\u001b[0m     is_model_pretrained, get_pretrained_cfg, get_pretrained_cfg_value\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\lib\\site-packages\\timm\\models\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbyobnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcait\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcoat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvmixer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1002\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:945\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1439\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1411\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1544\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from torchvision.ops import box_convert\n",
    "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "import openpyxl\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# 忽略特定警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*device.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*requires_grad.*\")\n",
    "\n",
    "# 使用 GPU 设备（如果可用）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 加载 GroundingDINO 模型\n",
    "cfg_path = r'D://code//CV//GroundingDINO//groundingdino//config//GroundingDINO_SwinT_OGC.py'\n",
    "weight_path = r'd://code//CV//GroundingDINO//weight//groundingdino_swint_ogc.pth'\n",
    "gdino_model = load_model(cfg_path, weight_path)\n",
    "gdino_model.to(device)\n",
    "BOX_THRESHOLD = 0.35\n",
    "TEXT_THRESHOLD = 0.35\n",
    "\n",
    "# 加载 Segment Anything 模型\n",
    "sam_checkpoint = r\"D://aigc//ComfyUI_windows_portable//ComfyUI//models//sams//sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def torch_gc():\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def process_images_in_folder_structure(input_folder, text_prompt):\n",
    "    total_files = 0\n",
    "    processed_files = 0\n",
    "    skipped_files = 0\n",
    "\n",
    "    second_level_folders = [f.path for f in os.scandir(input_folder) if f.is_dir()]\n",
    "\n",
    "    for second_folder in second_level_folders:\n",
    "        print(f\"Processing second level folder: {second_folder}\")\n",
    "\n",
    "        third_level_folders = [f.path for f in os.scandir(second_folder) if f.is_dir()]\n",
    "\n",
    "        for third_folder in third_level_folders:\n",
    "            print(f\"Processing third level folder: {third_folder}\")\n",
    "\n",
    "            output_folder = os.path.join(third_folder, 'grounding_output')\n",
    "            if not os.path.exists(output_folder):\n",
    "                os.makedirs(output_folder)\n",
    "\n",
    "            image_files = [f for f in os.listdir(third_folder) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "            total_files += len(image_files)\n",
    "\n",
    "            for filename in tqdm(image_files, desc=f\"Processing {third_folder}\"):\n",
    "                ip = os.path.join(third_folder, filename)\n",
    "                base_name = os.path.basename(ip).split('.')[0]\n",
    "                output_filename = f\"{base_name}.jpg\"\n",
    "                output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "                # 检查输出文件是否已存在\n",
    "                if os.path.exists(output_path):\n",
    "                    print(f\"Skipping {filename} as it has already been processed.\")\n",
    "                    skipped_files += 1\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    with torch_gc():\n",
    "                        image_source, boxes = get_box_from_gdino_with_text_prompt(ip, text_prompt)\n",
    "                        if image_source is not None and boxes is not None:\n",
    "                            seg_with_sam_with_box_prompt(image_source, boxes, text_prompt, output_folder, ip)\n",
    "                            processed_files += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"处理文件 {filename} 时出错: {e}\")\n",
    "                finally:\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"总文件数: {total_files}\")\n",
    "    print(f\"成功处理的文件数: {processed_files}\")\n",
    "    print(f\"跳过的文件数: {skipped_files}\")\n",
    "\n",
    "\n",
    "def get_box_from_gdino_with_text_prompt(ip, text_prompt):\n",
    "    try:\n",
    "        image_source, image = load_image(ip)\n",
    "        if image_source is None or image is None:\n",
    "            print(f\"无法加载图像: {ip}\")\n",
    "            return None, None\n",
    "\n",
    "        h, w = image_source.shape[:2]\n",
    "        boxes, logits, phrases = predict(\n",
    "            model=gdino_model,\n",
    "            image=image,\n",
    "            caption=text_prompt,\n",
    "            box_threshold=BOX_THRESHOLD,\n",
    "            text_threshold=TEXT_THRESHOLD,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # 尽早释放内存\n",
    "        del image\n",
    "        gc.collect()\n",
    "\n",
    "        boxes = boxes.to(device)\n",
    "        scale_tensor = torch.tensor([w, h, w, h], dtype=boxes.dtype, device=device)\n",
    "        boxes = boxes * scale_tensor\n",
    "        xyxy = box_convert(boxes=boxes, in_fmt=\"cxcywh\", out_fmt=\"xyxy\").cpu().numpy()\n",
    "\n",
    "        del logits, phrases, boxes, scale_tensor\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        return image_source, xyxy\n",
    "    except Exception as e:\n",
    "        print(f\"加载图像 {ip} 时出错: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def seg_with_sam_with_box_prompt(image, boxes, text_prompt, output_folder, ip):\n",
    "    predictor = SamPredictor(sam)\n",
    "    predictor.set_image(image)\n",
    "    merged_mask = np.zeros((image.shape[0], image.shape[1]), dtype=bool)\n",
    "    base_name = os.path.basename(ip).split('.')[0]\n",
    "\n",
    "    for idx, box in enumerate(boxes):\n",
    "        input_box = box.astype(int)\n",
    "        masks, _, _ = predictor.predict(\n",
    "            point_coords=None,\n",
    "            point_labels=None,\n",
    "            box=input_box[None, :],\n",
    "            multimask_output=False,\n",
    "        )\n",
    "        if masks is not None and len(masks) > 0:\n",
    "            mask = masks[0]\n",
    "            merged_mask = np.logical_or(merged_mask, mask)\n",
    "        del masks\n",
    "        gc.collect()\n",
    "\n",
    "    if np.any(merged_mask):\n",
    "        output_filename = f\"{base_name}.jpg\"\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        save_masked_image_using_pillow(image, merged_mask, output_path, boxes)\n",
    "\n",
    "        vertex_coords = [box for box in boxes]\n",
    "\n",
    "        excel_file = os.path.join(output_folder, 'grounding_results.xlsx')\n",
    "        update_excel(excel_file, base_name, boxes)\n",
    "\n",
    "\n",
    "def save_masked_image_using_pillow(image_np, mask_np, output_path, boxes):\n",
    "    from PIL import Image\n",
    "    image = Image.fromarray(image_np)\n",
    "    masked_image = Image.new('RGBA', image.size)\n",
    "    masked_image.paste(image, (0, 0))\n",
    "\n",
    "    # 将mask颜色改为蓝色（这里是RGB值）\n",
    "    blue_color = (0, 0, 255)\n",
    "    blue_mask_image = Image.new('L', image.size, 0)\n",
    "    blue_mask_image.putdata((mask_np * 255).astype('uint8').flatten())\n",
    "    blue_mask_image = blue_mask_image.convert('RGBA')\n",
    "    blue_mask_image_data = np.array(blue_mask_image)\n",
    "    blue_mask_image_data[blue_mask_image_data[:, :, 3] > 0] = [*blue_color, 255]\n",
    "    blue_mask_image = Image.fromarray(blue_mask_image_data)\n",
    "\n",
    "    masked_image = Image.alpha_composite(masked_image, blue_mask_image)\n",
    "\n",
    "    if masked_image.mode == 'RGBA':\n",
    "        masked_image = masked_image.convert('RGB')\n",
    "\n",
    "    masked_image.save(output_path)\n",
    "\n",
    "\n",
    "def update_excel(excel_file, base_name, boxes):\n",
    "    if not os.path.exists(excel_file):\n",
    "        workbook = openpyxl.Workbook()\n",
    "        worksheet = workbook.active\n",
    "        worksheet.append(['Image Name', 'x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'x4', 'y4'])\n",
    "        new_rows = []\n",
    "        for i, box in enumerate(boxes):\n",
    "            new_rows.append([\n",
    "                f\"{base_name}_{i + 1}\",\n",
    "                box[0], box[1],\n",
    "                box[2], box[1],\n",
    "                box[2], box[3],\n",
    "                box[0], box[3]\n",
    "            ])\n",
    "        for row in new_rows:\n",
    "            worksheet.append(row)\n",
    "        workbook.save(excel_file)\n",
    "    else:\n",
    "        workbook = openpyxl.load_workbook(excel_file)\n",
    "        worksheet = workbook.active\n",
    "        new_rows = []\n",
    "        for i, box in enumerate(boxes):\n",
    "            new_rows.append([\n",
    "                f\"{base_name}_{i + 1}\",\n",
    "                box[0], box[1],\n",
    "                box[2], box[1],\n",
    "                box[2], box[3],\n",
    "                box[0], box[3]\n",
    "            ])\n",
    "        for row in new_rows:\n",
    "            worksheet.append(row)\n",
    "        workbook.save(excel_file)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input_folder = \"D://code//data//Lv2期结论//test\"\n",
    "    text = 'person,shoes'\n",
    "    process_images_in_folder_structure(input_folder, text)\n",
    "    print('完结完结完结')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1602: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing second level folder: D://code//data//Lv2期结论//test\\testtest\n",
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\1047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\1047:   0%|          | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 63db832cF97eff165_b8c23b3d7354a1d4.jpg as it has already been processed.\n",
      "Skipping 65d70348Fd9d3b730_1f93b1aac6b19013.jpg as it has already been processed.\n",
      "Skipping 65d832a0F54b9d69b_fff2a9f29b14ab5b.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\1047:  11%|█▏        | 4/35 [00:00<00:07,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 65e5d29eF1f1b6f3c_8184751b68db81de.jpg as it has already been processed.\n",
      "Skipping 65f7f079F91869fb1_8b7fa71598a9e566.jpg as it has already been processed.\n",
      "Skipping 65ffa405F54ff1bcd_a3d59fb94b1454e9.jpg as it has already been processed.\n",
      "Skipping 6621c6d9Fe1c74db6_9a84a1bb41354eda.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\1047:  29%|██▊       | 10/35 [00:02<00:07,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 6642d40aFcee4e81f_7790f1f19c9494d6.jpg as it has already been processed.\n",
      "Skipping 6642d413F57f30ad6_7ca465cc42569902.jpg as it has already been processed.\n",
      "Skipping 6642d743F86abf9c4_c04d138ecf73ee98.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\1047:  40%|████      | 14/35 [00:03<00:05,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 665006ccFbdefecfe_9a6988ee7539a184.jpg as it has already been processed.\n",
      "Skipping 665401e4F769b24c9_5dffde2c8ec603fa.jpg as it has already been processed.\n",
      "Skipping 66603debF36effdd3_99dd2fbe801789cc.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\1047:  51%|█████▏    | 18/35 [00:04<00:04,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 66603f86F5de15492_484739571d8f415a.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\1047:  60%|██████    | 21/35 [00:06<00:05,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 66b1d88dFe4823d32_2a5b5d371844efd2.jpg as it has already been processed.\n",
      "Skipping 66bc60cfF3e635d22_8d7286782aac0d01.jpg as it has already been processed.\n",
      "Skipping 66bc60f4Fab0f90d3_1e4c9c0e275966ea.jpg as it has already been processed.\n",
      "Skipping 66c3f9c0F2b32c6c4_84059379959f2f9e.jpg as it has already been processed.\n",
      "Skipping 66c55cd4Fc04aa170_29d6a524f818876e.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\1047:  77%|███████▋  | 27/35 [00:07<00:02,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 66cd3c9dF6a814c11_c236c0258981d9fc.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\1047:  83%|████████▎ | 29/35 [00:08<00:01,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 66cd3c9dFb5775f7b_20c03b050875236a.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\1047: 100%|██████████| 35/35 [00:09<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 66cfca1dF71e6b42a_56b4f7e729bd3c7f.jpg as it has already been processed.\n",
      "Skipping 66d1268cF9068b7db_f21fb72b2a96b30c.jpg as it has already been processed.\n",
      "Skipping 66d126b7F4754eb99_632a4e3a7bbba38e.jpg as it has already been processed.\n",
      "Skipping 66f6be0bFf72ce107_417433bc78752844.jpg as it has already been processed.\n",
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\12010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\12010: 100%|██████████| 52/52 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 6565f210F73024a99_904f7c9025716558.jpg as it has already been processed.\n",
      "Skipping 65891d3bF6c095256_87f49a4cb51e321f.jpg as it has already been processed.\n",
      "Skipping 658e85edF1c160180_63306ff11eff4ec7.jpg as it has already been processed.\n",
      "Skipping 658e88ecF899d1529_a9d348003977bff2.jpg as it has already been processed.\n",
      "Skipping 65e9a9daF6e278143_1080ebe0b30e26d6.png as it has already been processed.\n",
      "Skipping 65ecffc5F35256008_a64eccd38dcbe1fe.jpg as it has already been processed.\n",
      "Skipping 65ed0016F4b9cad14_168a257b97bcb5c3.jpg as it has already been processed.\n",
      "Skipping 65ed0026F90135dfc_f1696b7df2ffa3dc.jpg as it has already been processed.\n",
      "Skipping 65ed0058Ffa0ff4ab_2ea287b3ea5a6628.jpg as it has already been processed.\n",
      "Skipping 65f39b99Fcd9c4f50_405bfaa72054482a.jpg as it has already been processed.\n",
      "Skipping 65f7dfd3F61b6b293_d12f8238d56c399e.png as it has already been processed.\n",
      "Skipping 65f956c6Fbe0738bd_b4c5f6e234f1695a.jpg as it has already been processed.\n",
      "Skipping 66542181Ff2882a1a_9734d63c04833eac.jpg as it has already been processed.\n",
      "Skipping 6654238bF75ce45b0_ec756e195e3a449e.jpg as it has already been processed.\n",
      "Skipping 6654a42eF2b9e7ec9_b3aa4a2ebc618673.jpg as it has already been processed.\n",
      "Skipping 6654a42eF60d2c782_f538f6492b340d5f.jpg as it has already been processed.\n",
      "Skipping 66615769F510256ef_4617b390d7ef513e.jpg as it has already been processed.\n",
      "Skipping 667065d1F430f3a6a_1ee2155189c22d84.jpg as it has already been processed.\n",
      "Skipping 667136f6F40708705_a0e09892d92d1796.jpg as it has already been processed.\n",
      "Skipping 667a8078Fca4bf6c3_4d325851ba961d8d.jpg as it has already been processed.\n",
      "Skipping 667aa30aFfbe55641_7014cae9cc7d8ff7.jpg as it has already been processed.\n",
      "Skipping 667bba47F022c2cd1_4d8c4e3c6c840530.jpg as it has already been processed.\n",
      "Skipping 667bbe0cF2b6046e3_d3926f7389f718a9.jpg as it has already been processed.\n",
      "Skipping 667bbe99F605a0b32_a2158f567780ad23.jpg as it has already been processed.\n",
      "Skipping 667bc613F7219c32f_707e416715499f79.jpg as it has already been processed.\n",
      "Skipping 667bceb5F4510f58c_ef132223200bda50.jpg as it has already been processed.\n",
      "Skipping 667bd0a2F399f5954_eef37c6882706024.jpg as it has already been processed.\n",
      "Skipping 667bd444F5fa4918c_e12b1a4c59fdd017.jpg as it has already been processed.\n",
      "Skipping 667bd4d6F4e34078b_11cf8c77532b6bca.jpg as it has already been processed.\n",
      "Skipping 667bd60bF6c8ae47c_46e44ab3b65f4379.jpg as it has already been processed.\n",
      "Skipping 667bd6ddF8b810aa2_a325e3567509c5cd.jpg as it has already been processed.\n",
      "Skipping 667bd7d7F823b3627_0c04493c1a83cd34.jpg as it has already been processed.\n",
      "Skipping 668b777fFb872145b_5b0badc905f05c2f.jpg as it has already been processed.\n",
      "Skipping 668b9997F1855d23a_97a05df41396ca0d.jpg as it has already been processed.\n",
      "Skipping 668ba1a6F6f56a891_9ad2bdaa15d4207c.jpg as it has already been processed.\n",
      "Skipping 668bb179F3faff749_7d1901b98fa0096c.jpg as it has already been processed.\n",
      "Skipping 668bbf5dF06b2443d_972fff5d5e24609a.jpg as it has already been processed.\n",
      "Skipping 668bc2c2Fd951932c_42118f557b4721f7.jpg as it has already been processed.\n",
      "Skipping 668bc4f1Fa9602334_5fd4819b9990df03.jpg as it has already been processed.\n",
      "Skipping 668bcf22Fa7aba566_589413f5ee363f6a.jpg as it has already been processed.\n",
      "Skipping 668cdb85F1057c8cf_8b882aa913de9f5c.jpg as it has already been processed.\n",
      "Skipping 668d27fdFdcb0126a_17deaaeae2ea26d4.jpg as it has already been processed.\n",
      "Skipping 668d3856F38a141af_2f030ce107c5a105.jpg as it has already been processed.\n",
      "Skipping 668d3c76F267d175d_1ae351809b108e03.jpg as it has already been processed.\n",
      "Skipping 6690b38cFd076501e_e1dadfc263b57f8a.jpg as it has already been processed.\n",
      "Skipping 66948914Fcbf38006_8570d76ee2ec9a60.jpg as it has already been processed.\n",
      "Skipping 66bed07cF9c06adb3_b8bd35c8b68c4fbb.jpg as it has already been processed.\n",
      "Skipping 66c5db3dF25d22c2e_066e83911d284e5a.jpg as it has already been processed.\n",
      "Skipping 66c8527aFba9b3742_5c42d51d9611feaa.jpg as it has already been processed.\n",
      "Skipping 66cca4f6F023f007e_96c47b2828f4a85e.jpg as it has already been processed.\n",
      "Skipping 66cf03baF97faea2e_24451934578cb6e7.jpg as it has already been processed.\n",
      "Skipping 66d18e71F9429fd26_d6eb4de8b6d65113.jpg as it has already been processed.\n",
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\12811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\12811:   0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 6527912bF3e2522ba_0ae201b7c192b24e.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\12811:   6%|▋         | 3/47 [00:01<00:28,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 662bb08dF0c3bc427_2bb53d12008183de.jpg as it has already been processed.\n",
      "Skipping 662f8387Fa05441cc_65aa48abc58455f8.jpg as it has already been processed.\n",
      "Skipping 6630ca68Fa8b8dd29_9618c0199bb5623e.jpg as it has already been processed.\n",
      "Skipping 6638b847Fb3eaf6c7_023bf078f567d422.jpg as it has already been processed.\n",
      "Skipping 6642179dF7a90f459_c90b42e5bd3d7a42.png as it has already been processed.\n",
      "Skipping 6642cd4aF1e03ec19_bf430a96fa95f935.jpg as it has already been processed.\n",
      "Skipping 6642cd61F5a28dff7_e8bbe9bb7478bdc8.jpg as it has already been processed.\n",
      "Skipping 6642ce40F2bf57dfa_e692bd3567249cfd.jpg as it has already been processed.\n",
      "Skipping 6642ce9cFbb4a5c0b_320b13137ab90842.jpg as it has already been processed.\n",
      "Skipping 664335a5F970e7986_eba777191c73ab68.jpg as it has already been processed.\n",
      "Skipping 664335a5Fe9eb149b_db49def7fccf1d70.jpg as it has already been processed.\n",
      "Skipping 664335a6F1e447832_63ef48e20f85806e.jpg as it has already been processed.\n",
      "Skipping 664335a7Fba16e636_300a60cbd2990d55.jpg as it has already been processed.\n",
      "Skipping 664ee450F28b6c4b4_a9e63e862909047c.jpg as it has already been processed.\n",
      "Skipping 664f099dF1504dfa5_3d2db5f371fe1d8d.jpg as it has already been processed.\n",
      "Skipping 6653f1deFd55f2814_7dc4a315c7ed76d8.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\12811:  43%|████▎     | 20/47 [00:02<00:02,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 665447daF2105c168_ed24bd41d1bd2344.jpg as it has already been processed.\n",
      "Skipping 665448abFf657ca74_66b6189bcece79f3.jpg as it has already been processed.\n",
      "Skipping 6655963bF1bbfc012_69e9b120ca12e5df.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\12811:  51%|█████     | 24/47 [00:03<00:03,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 66594c6fFf2281125_565a6fc22d13dcf0.jpg as it has already been processed.\n",
      "Skipping 66594c8fF5097cf02_489db558ff5dcca8.jpg as it has already been processed.\n",
      "Skipping 665b532dF75c1d752_9fcf4c1363414b1d.jpg as it has already been processed.\n",
      "Skipping 665ec93aFfd14f2f2_1c7895ba4f491cb4.jpg as it has already been processed.\n",
      "Skipping 667d0ab7Fd3cef66c_902f49b760cfe20c.jpg as it has already been processed.\n",
      "Skipping 66964330F25660533_9ba77d7789150350.jpg as it has already been processed.\n",
      "Skipping 66964331F25d06f50_9141252fdaa4c661.jpg as it has already been processed.\n",
      "Skipping 66964331Ffe297c37_0bb9ac6088709610.jpg as it has already been processed.\n",
      "Skipping 66964333F32bf3277_5b5fd9edbd1c6735.jpg as it has already been processed.\n",
      "Skipping 66973325F910a38ae_bc177f72a5676983.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\12811:  74%|███████▍  | 35/47 [00:04<00:01,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 669734eaF17b2d382_f0c3b14dc71f454f.jpg as it has already been processed.\n",
      "Skipping 669734efFe07b2064_d0d97f0d436dec20.jpg as it has already been processed.\n",
      "Skipping 66b57ec1Fc87e15f1_a951a9b50dd7627b.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\12811:  83%|████████▎ | 39/47 [00:05<00:01,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 66beb4cbFe9c7f99f_0b42a0a35c2ba9a1.jpg as it has already been processed.\n",
      "Skipping 66beb859F4f9762cd_22f53779f1b8891e.jpg as it has already been processed.\n",
      "Skipping 66beb971Fb943fa5f_f9ca61cbdafd9ff8.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\12811:  91%|█████████▏| 43/47 [00:06<00:00,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 66c30a31F48c082d9_ce5a2b2e1d0053aa.jpg as it has already been processed.\n",
      "Skipping 66cc44d4Fcdc2badb_46c3b9b101548465.jpg as it has already been processed.\n",
      "Skipping 66cc524eF5808f5ab_873444e1ed2e5230.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\12811: 100%|██████████| 47/47 [00:07<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\1349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\1349:   0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 662a0f61F6b549964_6e164a1b9d94c761.jpg as it has already been processed.\n",
      "Skipping 6645a767Fc79748f5_447f6562edb3bf70.jpg as it has already been processed.\n",
      "Skipping 6645a76bF9d399120_e6d7e08dec745a8f.jpg as it has already been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\1349: 100%|██████████| 74/74 [01:18<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\1355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\1355: 100%|██████████| 122/122 [02:13<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\13661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\13661: 100%|██████████| 38/38 [00:43<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\1476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\1476: 100%|██████████| 3/3 [00:03<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\15908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\15908: 100%|██████████| 54/54 [00:56<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\1656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\1656: 100%|██████████| 41/41 [00:48<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\1657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\1657: 100%|██████████| 82/82 [01:35<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\16777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\16777: 100%|██████████| 102/102 [01:55<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\34919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\34919: 100%|██████████| 52/52 [00:53<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\35404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\35404: 100%|██████████| 83/83 [01:38<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\6191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\6191: 100%|██████████| 24/24 [00:26<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\6221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\6221: 100%|██████████| 38/38 [00:41<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\739: 100%|██████████| 93/93 [01:46<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\753: 100%|██████████| 28/28 [00:29<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\760: 100%|██████████| 59/59 [01:03<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\9435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\9435: 100%|██████████| 178/178 [03:08<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing third level folder: D://code//data//Lv2期结论//test\\testtest\\9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing D://code//data//Lv2期结论//test\\testtest\\9775: 100%|██████████| 33/33 [00:45<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总文件数: 1238\n",
      "成功处理的文件数: 1119\n",
      "跳过的文件数: 119\n",
      "完结完结完结\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from torchvision.ops import box_convert\n",
    "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "import openpyxl\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# 忽略特定警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*device.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*requires_grad.*\")\n",
    "\n",
    "# 使用 GPU 设备（如果可用）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 加载 GroundingDINO 模型\n",
    "cfg_path = r'D://code//CV//GroundingDINO//groundingdino//config//GroundingDINO_SwinT_OGC.py'\n",
    "weight_path = r'd://code//CV//GroundingDINO//weight//groundingdino_swint_ogc.pth'\n",
    "gdino_model = load_model(cfg_path, weight_path)\n",
    "gdino_model.to(device)\n",
    "BOX_THRESHOLD = 0.35\n",
    "TEXT_THRESHOLD = 0.35\n",
    "\n",
    "# 加载 Segment Anything 模型\n",
    "sam_checkpoint = r\"D://aigc//ComfyUI_windows_portable//ComfyUI//models//sams//sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def torch_gc():\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def process_images_in_folder_structure(input_folder, text_prompt):\n",
    "    total_files = 0\n",
    "    processed_files = 0\n",
    "    skipped_files = 0\n",
    "\n",
    "    second_level_folders = [f.path for f in os.scandir(input_folder) if f.is_dir()]\n",
    "\n",
    "    for second_folder in second_level_folders:\n",
    "        print(f\"Processing second level folder: {second_folder}\")\n",
    "\n",
    "        third_level_folders = [f.path for f in os.scandir(second_folder) if f.is_dir()]\n",
    "\n",
    "        for third_folder in third_level_folders:\n",
    "            print(f\"Processing third level folder: {third_folder}\")\n",
    "\n",
    "            output_folder = os.path.join(third_folder, 'grounding_output')\n",
    "            if not os.path.exists(output_folder):\n",
    "                os.makedirs(output_folder)\n",
    "\n",
    "            image_files = [f for f in os.listdir(third_folder) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "            total_files += len(image_files)\n",
    "\n",
    "            for filename in tqdm(image_files, desc=f\"Processing {third_folder}\"):\n",
    "                ip = os.path.join(third_folder, filename)\n",
    "                base_name = os.path.basename(ip).split('.')[0]\n",
    "                output_filename = f\"{base_name}.jpg\"\n",
    "                output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "                # 检查输出文件是否已存在\n",
    "                if os.path.exists(output_path):\n",
    "                    print(f\"Skipping {filename} as it has already been processed.\")\n",
    "                    skipped_files += 1\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    with torch_gc():\n",
    "                        image_source, boxes = get_box_from_gdino_with_text_prompt(ip, text_prompt)\n",
    "                        if image_source is not None and boxes is not None:\n",
    "                            seg_with_sam_with_box_prompt(image_source, boxes, text_prompt, output_folder, ip)\n",
    "                            processed_files += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"处理文件 {filename} 时出错: {e}\")\n",
    "                finally:\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"总文件数: {total_files}\")\n",
    "    print(f\"成功处理的文件数: {processed_files}\")\n",
    "    print(f\"跳过的文件数: {skipped_files}\")\n",
    "\n",
    "\n",
    "def get_box_from_gdino_with_text_prompt(ip, text_prompt):\n",
    "    try:\n",
    "        image_source, image = load_image(ip)\n",
    "        if image_source is None or image is None:\n",
    "            print(f\"无法加载图像: {ip}\")\n",
    "            return None, None\n",
    "\n",
    "        h, w = image_source.shape[:2]\n",
    "        boxes, logits, phrases = predict(\n",
    "            model=gdino_model,\n",
    "            image=image,\n",
    "            caption=text_prompt,\n",
    "            box_threshold=BOX_THRESHOLD,\n",
    "            text_threshold=TEXT_THRESHOLD,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # 尽早释放内存\n",
    "        del image\n",
    "        gc.collect()\n",
    "\n",
    "        boxes = boxes.to(device)\n",
    "        scale_tensor = torch.tensor([w, h, w, h], dtype=boxes.dtype, device=device)\n",
    "        boxes = boxes * scale_tensor\n",
    "        xyxy = box_convert(boxes=boxes, in_fmt=\"cxcywh\", out_fmt=\"xyxy\").cpu().numpy()\n",
    "\n",
    "        del logits, phrases, boxes, scale_tensor\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        return image_source, xyxy\n",
    "    except Exception as e:\n",
    "        print(f\"加载图像 {ip} 时出错: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def seg_with_sam_with_box_prompt(image, boxes, text_prompt, output_folder, ip):\n",
    "    predictor = SamPredictor(sam)\n",
    "    predictor.set_image(image)\n",
    "    merged_mask = None\n",
    "    base_name = os.path.basename(ip).split('.')[0]\n",
    "\n",
    "    for idx, box in enumerate(boxes):\n",
    "        input_box = box.astype(int)\n",
    "        masks, _, _ = predictor.predict(\n",
    "            point_coords=None,\n",
    "            point_labels=None,\n",
    "            box=input_box[None, :],\n",
    "            multimask_output=False,\n",
    "        )\n",
    "        if masks is not None and len(masks) > 0:\n",
    "            if merged_mask is None:\n",
    "                merged_mask = masks[0]\n",
    "            else:\n",
    "                merged_mask = np.logical_or(merged_mask, masks[0])\n",
    "        # 及时释放内存\n",
    "        del masks\n",
    "        gc.collect()\n",
    "\n",
    "    if merged_mask is not None:\n",
    "        merged_mask = np.where(merged_mask > 0, 1, 0)\n",
    "        if np.any(merged_mask):\n",
    "            output_filename = f\"{base_name}.jpg\"\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            save_masked_image_using_pillow(image, merged_mask, output_path, boxes)\n",
    "\n",
    "            vertex_coords = [box for box in boxes]\n",
    "\n",
    "            excel_file = os.path.join(output_folder, 'grounding_results.xlsx')\n",
    "            update_excel(excel_file, base_name, boxes)\n",
    "\n",
    "\n",
    "def save_masked_image_using_pillow(image_np, mask_np, output_path, boxes):\n",
    "    from PIL import Image, ImageDraw\n",
    "    \n",
    "    # 将numpy数组转换为PIL图像\n",
    "    image = Image.fromarray(image_np)\n",
    "    \n",
    "    # 创建一个与原始图像相同大小的RGBA图像\n",
    "    result_image = Image.new('RGBA', image.size)\n",
    "    result_image.paste(image, (0, 0))  # 首先粘贴原始图像\n",
    "    \n",
    "    # 创建蓝色遮罩\n",
    "    blue_mask = Image.new('RGBA', image.size, (0, 0, 255, 128))  # 半透明蓝色\n",
    "    mask_image = Image.fromarray((mask_np * 255).astype('uint8'))\n",
    "    \n",
    "    # 将蓝色遮罩应用到目标区域\n",
    "    result_image.paste(blue_mask, (0, 0), mask_image)\n",
    "    \n",
    "    # # 绘制边界框\n",
    "    # draw = ImageDraw.Draw(result_image)\n",
    "    # for box in boxes:\n",
    "    #     draw.rectangle(box.tolist(), outline='red', width=2)\n",
    "    \n",
    "    # 如果需要保存为JPG格式，转换为RGB模式\n",
    "    if output_path.lower().endswith('.jpg'):\n",
    "        result_image = result_image.convert('RGB')\n",
    "    \n",
    "    # 保存结果\n",
    "    result_image.save(output_path)\n",
    "\n",
    "\n",
    "def update_excel(excel_file, base_name, boxes):\n",
    "    if not os.path.exists(excel_file):\n",
    "        workbook = openpyxl.Workbook()\n",
    "        worksheet = workbook.active\n",
    "        worksheet.append(['Image Name', 'x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'x4', 'y4'])\n",
    "        new_rows = []\n",
    "        for i, box in enumerate(boxes):\n",
    "            new_rows.append([\n",
    "                f\"{base_name}_{i + 1}\",\n",
    "                box[0], box[1],\n",
    "                box[2], box[1],\n",
    "                box[2], box[3],\n",
    "                box[0], box[3]\n",
    "            ])\n",
    "        for row in new_rows:\n",
    "            worksheet.append(row)\n",
    "        workbook.save(excel_file)\n",
    "    else:\n",
    "        workbook = openpyxl.load_workbook(excel_file)\n",
    "        worksheet = workbook.active\n",
    "        new_rows = []\n",
    "        for i, box in enumerate(boxes):\n",
    "            new_rows.append([\n",
    "                f\"{base_name}_{i + 1}\",\n",
    "                box[0], box[1],\n",
    "                box[2], box[1],\n",
    "                box[2], box[3],\n",
    "                box[0], box[3]\n",
    "            ])\n",
    "        for row in new_rows:\n",
    "            worksheet.append(row)\n",
    "        workbook.save(excel_file)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input_folder = \"D://code//data//Lv2期结论//test\"\n",
    "    text = 'person,shoes'\n",
    "    process_images_in_folder_structure(input_folder, text)\n",
    "    print('完结完结完结')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_layer_cases = [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]\n",
    "\n",
    "filter_suffix_list = ['filter_1.0_2.0','filter_3.0_4.0','filter_5.0_6.0']\n",
    "\n",
    "\n",
    "x_list = ['9783','6913','6912','6911','6910','6909','6908','12066']\n",
    "y_list = ['txt', 'price']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
