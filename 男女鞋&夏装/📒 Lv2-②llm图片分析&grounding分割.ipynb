{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stpe1 - 利用LLM来对图片进行分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取一个文件夹,\n",
    "\n",
    "\n",
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import ujson as json\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# 设置API密钥和基础URL\n",
    "api_key = \"35f54cc4-be7a-4414-808e-f5f9f0194d4f\"\n",
    "api_base = \"http://gpt-proxy.jd.com/v1/chat/completions\"\n",
    "client = OpenAI(api_key=api_key, base_url=api_base)\n",
    "\n",
    "\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image folder\n",
    "image_folder = \"D://code//data//background_color//服饰鞋靴箱包//女士春夏上装//grounding_output//test1\"\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop through each image in the folder\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        base64_image = encode_image(image_path)\n",
    "\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {api_key}\"\n",
    "        }\n",
    "\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": '''\n",
    "                                    你是一个优秀的设计师和数据分析师. 请描述画面的整体类型, 需要包含如下维度:\n",
    "                                    1.价促类型(只要出现价格信息/促销信息/满减/买赠等营销活动信息),功能类型(以商品功能/卖点/细节等信息为主),白底图(背景为白色的图片),场景图(背景为非白底图);\n",
    "                                    2.请描述画面中背景的视觉风格/色彩/背景中包含的视觉元素/是否模糊/背景类型风格\n",
    "                                    3.请描述画面中是否存在logo\n",
    "                                    4.请描述是否存在除商品主体外的小元素, 小元素的定义是指商品主体和logo以外的非文字类的元素(特别注意不要统计文字类),被单独分割出来,通常周边会填充颜色以和背景区别, 如: 图案/图标/形状/等, 并给出矩形框坐标;\n",
    "                                    5.请描述是否存在除商品主体外的细节图,细节图的定义是指商品主体以外的元素, 被单独分割出来, 通常周边会填充颜色以和背景区别, 如:放大的局部/材质描述/功能描述等,并给出矩形框坐标\n",
    "\n",
    "                                    以上结果需要按照统一的格式输出: \n",
    "                                    画面类型(价促类or功能类or白底图or场景图);\n",
    "                                    商品主体(具体的商品主体描述, 坐标(x1,y1), (x2,y2)); \n",
    "                                    视觉风格(具体的视觉风格描述); 色彩(具体色彩描述); \n",
    "                                    元素(具体的元素描述);\n",
    "                                    是否模糊(模糊或清晰);\n",
    "                                    小元素(是or否,描述元素内容,给出矩形框坐标);\n",
    "                                    细节图(是or否,描述细节内容,给出矩形框坐标) ; \n",
    "                                    画面内容(具体的文字描述, 如果是前面已经出现过的内容就不要描述);\n",
    "                                    '''\n",
    "\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 700\n",
    "        }\n",
    "\n",
    "        response = requests.post(\"http://gpt-proxy.jd.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "        # print(response.json())\n",
    "\n",
    "        result = response.json()\n",
    "        generated_text = result['choices'][0]['message']['content']\n",
    "        # print(generated_text)\n",
    "\n",
    "    # Create a dictionary with the image filename and generated text\n",
    "        image_result = {\"filename\": filename, \"generated_text\": generated_text}\n",
    "        results.append(image_result)\n",
    "\n",
    "\n",
    "\n",
    "# # Save the results as a JSON file\n",
    "# with open('D://code//data//background_color//服饰鞋靴箱包//女士春夏上装//grounding_output//test1//image_results.json', 'w') as f:\n",
    "#     json.dump(results, f, indent=4)\n",
    "\n",
    "# Save the results as an Excel file\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel('D://code//data//background_color//服饰鞋靴箱包//女士春夏上装//grounding_output//test1//image_results.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step2 - 将图片进行分割\n",
    "增加了对已分割图片的识别和跳过功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1602: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing second level folder: D://code//data//Lv2期结论//女鞋_from_0501//test\\6917\n",
      "总文件数: 0\n",
      "成功处理的文件数: 0\n",
      "跳过的文件数: 0\n",
      "完结完结完结\n"
     ]
    }
   ],
   "source": [
    "# # 经过cursor内存优化后的代码\n",
    "\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import gc\n",
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# from torchvision.ops import box_convert\n",
    "# from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "# from segment_anything import sam_model_registry, SamPredictor\n",
    "# import openpyxl\n",
    "# from contextlib import contextmanager\n",
    "\n",
    "# # 忽略特定警告\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*device.*\")\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*requires_grad.*\")\n",
    "\n",
    "# # 使用 GPU 设备（如果可用）\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# # 加载 GroundingDINO 模型\n",
    "# cfg_path = r'D://code//CV//GroundingDINO//groundingdino//config//GroundingDINO_SwinT_OGC.py'\n",
    "# weight_path = r'd://code//CV//GroundingDINO//weight//groundingdino_swint_ogc.pth'\n",
    "# gdino_model = load_model(cfg_path, weight_path)\n",
    "# gdino_model.to(device)\n",
    "# BOX_THRESHOLD = 0.35\n",
    "# TEXT_THRESHOLD = 0.35\n",
    "\n",
    "# # 加载 Segment Anything 模型\n",
    "# sam_checkpoint = r\"D://aigc//ComfyUI_windows_portable//ComfyUI//models//sams//sam_vit_h_4b8939.pth\"\n",
    "# model_type = \"vit_h\"\n",
    "# sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "# sam.to(device)\n",
    "\n",
    "# @contextmanager\n",
    "# def torch_gc():\n",
    "#     try:\n",
    "#         yield\n",
    "#     finally:\n",
    "#         gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "# def process_images_in_folder_structure(input_folder, text_prompt):\n",
    "#     total_files = 0\n",
    "#     processed_files = 0\n",
    "#     skipped_files = 0\n",
    "\n",
    "#     second_level_folders = [f.path for f in os.scandir(input_folder) if f.is_dir()]\n",
    "\n",
    "#     for second_folder in second_level_folders:\n",
    "#         print(f\"Processing second level folder: {second_folder}\")\n",
    "        \n",
    "#         third_level_folders = [f.path for f in os.scandir(second_folder) if f.is_dir()]\n",
    "\n",
    "#         for third_folder in third_level_folders:\n",
    "#             print(f\"Processing third level folder: {third_folder}\")\n",
    "            \n",
    "#             output_folder = os.path.join(third_folder, 'grounding_output')\n",
    "#             if not os.path.exists(output_folder):\n",
    "#                 os.makedirs(output_folder)\n",
    "\n",
    "#             image_files = [f for f in os.listdir(third_folder) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "#             total_files += len(image_files)\n",
    "\n",
    "#             for filename in tqdm(image_files, desc=f\"Processing {third_folder}\"):\n",
    "#                 ip = os.path.join(third_folder, filename)\n",
    "#                 base_name = os.path.basename(ip).split('.')[0]\n",
    "#                 output_filename = f\"{base_name}.jpg\"\n",
    "#                 output_path = os.path.join(output_folder, output_filename)\n",
    "                \n",
    "#                 # 检查输出文件是否已存在\n",
    "#                 if os.path.exists(output_path):\n",
    "#                     print(f\"Skipping {filename} as it has already been processed.\")\n",
    "#                     skipped_files += 1\n",
    "#                     continue\n",
    "\n",
    "#                 try:\n",
    "#                     with torch_gc():\n",
    "#                         image, boxes = get_box_from_gdino_with_text_prompt(ip, text_prompt)\n",
    "#                         if image is not None and boxes is not None:\n",
    "#                             seg_with_sam_with_box_prompt(image, boxes, text_prompt, output_folder, ip)\n",
    "#                             processed_files += 1\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"处理文件 {filename} 时出错: {e}\")\n",
    "#                 finally:\n",
    "#                     plt.close('all')\n",
    "#                     gc.collect()\n",
    "#                     torch.cuda.empty_cache()\n",
    "\n",
    "#     print(f\"总文件数: {total_files}\")\n",
    "#     print(f\"成功处理的文件数: {processed_files}\")\n",
    "#     print(f\"跳过的文件数: {skipped_files}\")\n",
    "\n",
    "\n",
    "# def get_box_from_gdino_with_text_prompt(ip, text_prompt):\n",
    "#     try:\n",
    "#         image_source, image = load_image(ip)\n",
    "#         if image_source is None or image is None:\n",
    "#             print(f\"无法加载图像: {ip}\")\n",
    "#             return None, None\n",
    "\n",
    "#         h, w = image_source.shape[:2]\n",
    "#         boxes, logits, phrases = predict(\n",
    "#             model=gdino_model,\n",
    "#             image=image,\n",
    "#             caption=text_prompt,\n",
    "#             box_threshold=BOX_THRESHOLD,\n",
    "#             text_threshold=TEXT_THRESHOLD,\n",
    "#             device=device\n",
    "#         )\n",
    "\n",
    "#         boxes = boxes.to(device)\n",
    "#         scale_tensor = torch.tensor([w, h, w, h], dtype=boxes.dtype, device=device)\n",
    "#         boxes = boxes * scale_tensor\n",
    "#         xyxy = box_convert(boxes=boxes, in_fmt=\"cxcywh\", out_fmt=\"xyxy\").cpu().numpy()\n",
    "\n",
    "#         del image, logits, phrases, boxes, scale_tensor\n",
    "#         gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "#         return image_source, xyxy\n",
    "#     except Exception as e:\n",
    "#         print(f\"加载图像 {ip} 时出错: {e}\")\n",
    "#         return None, None\n",
    "\n",
    "# def seg_with_sam_with_box_prompt(image, boxes, text_prompt, output_folder, ip):\n",
    "#     predictor = SamPredictor(sam)\n",
    "#     predictor.set_image(image)\n",
    "#     merged_mask = None\n",
    "\n",
    "#     for idx, box in enumerate(boxes):\n",
    "#         input_box = box.astype(int)\n",
    "#         masks, _, _ = predictor.predict(\n",
    "#             point_coords=None,\n",
    "#             point_labels=None,\n",
    "#             box=input_box[None, :],\n",
    "#             multimask_output=False,\n",
    "#         )\n",
    "#         if masks is not None and len(masks) > 0:\n",
    "#             if merged_mask is None:\n",
    "#                 merged_mask = masks[0]\n",
    "#             else:\n",
    "#                 merged_mask = np.logical_or(merged_mask, masks[0])\n",
    "\n",
    "#     if merged_mask is not None:\n",
    "#         merged_mask = np.where(merged_mask > 0, 1, 0)\n",
    "#         if np.any(merged_mask):\n",
    "#             base_name = os.path.basename(ip).split('.')[0]\n",
    "#             output_filename = f\"{base_name}.jpg\"\n",
    "#             output_path = os.path.join(output_folder, output_filename)\n",
    "#             save_masked_image(image, merged_mask, output_path, boxes)\n",
    "\n",
    "#             vertex_coords = [box for box in boxes]\n",
    "\n",
    "#             excel_file = os.path.join(output_folder, 'grounding_results.xlsx')\n",
    "#             if not os.path.exists(excel_file):\n",
    "#                 workbook = openpyxl.Workbook()\n",
    "#                 worksheet = workbook.active\n",
    "#                 worksheet.append(['Image Name', 'x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'x4', 'y4'])\n",
    "#             else:\n",
    "#                 workbook = openpyxl.load_workbook(excel_file)\n",
    "#                 worksheet = workbook.active\n",
    "\n",
    "#             seen_vertices = set()\n",
    "#             for i, box in enumerate(boxes):\n",
    "#                 if base_name not in set(worksheet['A']):\n",
    "#                     worksheet.append([\n",
    "#                         f\"{base_name}_{i + 1}\",\n",
    "#                         box[0], box[1],\n",
    "#                         box[2], box[1],\n",
    "#                         box[2], box[3],\n",
    "#                         box[0], box[3]\n",
    "#                     ])\n",
    "\n",
    "#             workbook.save(excel_file)\n",
    "\n",
    "#     del predictor, masks\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "# def save_masked_image(image, mask, output_path, boxes):\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "#     plt.imshow(image)\n",
    "#     show_mask(mask, plt.gca())\n",
    "\n",
    "#     plt.axis('off')\n",
    "#     plt.savefig(output_path, dpi=100, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "#     plt.close('all')\n",
    "#     gc.collect()\n",
    "\n",
    "# def show_mask(mask, ax, random_color=False):\n",
    "#     color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0) if random_color else np.array(\n",
    "#         [30 / 255, 144 / 255, 255 / 255, 1])\n",
    "#     h, w = mask.shape[-2:]\n",
    "#     mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "#     ax.imshow(mask_image)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     input_folder = \"D://code//data//Lv2期结论//女鞋_from_0501//test\"\n",
    "#     text = 'person,shoes'\n",
    "#     process_images_in_folder_structure(input_folder, text)\n",
    "#     print('完结完结完结')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1602: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Processing D://code//data//Lv2期结论//女鞋_from_0501//test//6917: 100%|██████████| 1790/1790 [1:12:55<00:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完结完结完结\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.ops import box_convert\n",
    "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "import openpyxl\n",
    "\n",
    "# 忽略特定警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*device.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*requires_grad.*\")\n",
    "\n",
    "# 使用 CPU 设备\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 加载 GroundingDINO 模型\n",
    "cfg_path = r'D://code//CV//GroundingDINO//groundingdino//config//GroundingDINO_SwinT_OGC.py'\n",
    "weight_path = r'd://code//CV//GroundingDINO//weight//groundingdino_swint_ogc.pth'\n",
    "gdino_model = load_model(cfg_path, weight_path)\n",
    "gdino_model.to(device)\n",
    "BOX_THRESHOLD = 0.35\n",
    "TEXT_THRESHOLD = 0.35\n",
    "\n",
    "# 加载 Segment Anything 模型\n",
    "sam_checkpoint = r\"D://aigc//ComfyUI_windows_portable//ComfyUI//models//sams//sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device)\n",
    "\n",
    "def process_images_in_folder(input_folder, text_prompt):\n",
    "    # 创建输出文件夹\n",
    "    output_folder = os.path.join(input_folder, 'grounding_output')\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    processed_files = set()  # 新增的集合，用于跟踪已处理的文件\n",
    "\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        if root == input_folder:  # 新增的判断条件，只处理根目录的图片\n",
    "            for filename in tqdm(files, desc=f\"Processing {root}\"):\n",
    "                if filename.endswith((\".jpg\", \".png\")):\n",
    "                    ip = os.path.join(root, filename)\n",
    "                    if ip not in processed_files:  # 检查文件是否已经被处理\n",
    "                        try:\n",
    "                            image, boxes = get_box_from_gdino_with_text_prompt(ip, text_prompt)\n",
    "                            if image is not None and boxes is not None:\n",
    "                                seg_with_sam_with_box_prompt(image, boxes, text_prompt, output_folder, ip)\n",
    "                        except Exception as e:\n",
    "                            print(f\"处理文件 {filename} 时出错: {e}\")\n",
    "                        finally:\n",
    "                            plt.close('all')\n",
    "                            gc.collect()\n",
    "                        processed_files.add(ip)  # 将文件添加到已处理文件集合中\n",
    "\n",
    "def get_box_from_gdino_with_text_prompt(ip, text_prompt):\n",
    "    try:\n",
    "        image_source, image = load_image(ip)\n",
    "        if image_source is None or image is None:\n",
    "            print(f\"无法加载图像: {ip}\")\n",
    "            return None, None\n",
    "\n",
    "        h, w = image_source.shape[:2]\n",
    "        boxes, logits, phrases = predict(\n",
    "            model=gdino_model,\n",
    "            image=image,\n",
    "            caption=text_prompt,\n",
    "            box_threshold=BOX_THRESHOLD,\n",
    "            text_threshold=TEXT_THRESHOLD,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # 确保 boxes 在正确的设备上\n",
    "        boxes = boxes.to(device)\n",
    "        \n",
    "        # 创建缩放张量并移动到正确的设备\n",
    "        scale_tensor = torch.tensor([w, h, w, h], dtype=boxes.dtype, device=device)\n",
    "        \n",
    "        # 进行缩放操作\n",
    "        boxes = boxes * scale_tensor\n",
    "        \n",
    "        # 转换坐标格式\n",
    "        xyxy = box_convert(boxes=boxes, in_fmt=\"cxcywh\", out_fmt=\"xyxy\").cpu().numpy()\n",
    "        \n",
    "        del image, logits, phrases, boxes, scale_tensor\n",
    "        gc.collect()\n",
    "        return image_source, xyxy\n",
    "    except Exception as e:\n",
    "        print(f\"加载图像 {ip} 时出错: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def seg_with_sam_with_box_prompt(image, boxes, text_prompt, output_folder, ip):\n",
    "    predictor = SamPredictor(sam)\n",
    "    predictor.set_image(image)\n",
    "    merged_mask = None\n",
    "\n",
    "    for idx, box in enumerate(boxes):\n",
    "        input_box = box.astype(int)\n",
    "        masks, _, _ = predictor.predict(\n",
    "            point_coords=None,\n",
    "            point_labels=None,\n",
    "            box=input_box[None, :],\n",
    "            multimask_output=False,\n",
    "        )\n",
    "        if masks is not None and len(masks) > 0:\n",
    "            if merged_mask is None:\n",
    "                merged_mask = masks[0]\n",
    "            else:\n",
    "                merged_mask += masks[0]\n",
    "\n",
    "    if merged_mask is not None:\n",
    "        merged_mask = np.where(merged_mask > 0, 1, 0)\n",
    "        if np.any(merged_mask):\n",
    "            base_name = os.path.basename(ip).split('.')[0]\n",
    "            output_filename = f\"{base_name}.jpg\"\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            save_masked_image(image, merged_mask, output_path, boxes)\n",
    "\n",
    "            # 记录四个顶点的坐标\n",
    "            vertex_coords = [box for box in boxes]\n",
    "\n",
    "            # 将图片名和坐标保存到Excel文件中\n",
    "            base_name = os.path.basename(ip).split('.')[0]\n",
    "            excel_file = os.path.join(output_folder, 'grounding_results.xlsx')\n",
    "            if not os.path.exists(excel_file):\n",
    "                workbook = openpyxl.Workbook()\n",
    "                worksheet = workbook.active\n",
    "                worksheet.append(['Image Name', 'x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'x4', 'y4'])\n",
    "            else:\n",
    "                workbook = openpyxl.load_workbook(excel_file)\n",
    "                worksheet = workbook.active\n",
    "\n",
    "            seen_vertices = set()\n",
    "            for i, box in enumerate(boxes):\n",
    "                # 检查图像名称是否已经在Excel中\n",
    "                if base_name not in set(worksheet['A']):\n",
    "                    worksheet.append([\n",
    "                        f\"{base_name}_{i+1}\",\n",
    "                        box[0], box[1],  # 左上角顶点\n",
    "                        box[2], box[1],  # 右上角顶点\n",
    "                        box[2], box[3],  # 右下角顶点\n",
    "                        box[0], box[3]   # 左下角顶点\n",
    "                    ])\n",
    "\n",
    "            workbook.save(excel_file)\n",
    "\n",
    "def save_masked_image(image, mask, output_path, boxes):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image)\n",
    "    show_mask(mask, plt.gca())\n",
    "\n",
    "    # 绘制矩形框\n",
    "    # for box in boxes:\n",
    "        # plt.gca().add_patch(plt.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], fill=False, edgecolor='r', linewidth=2))\n",
    "        # plt.gca().add_patch(plt.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], fill=False,  linewidth=2))\n",
    "\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.savefig(output_path, dpi=100, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "    plt.close('all')\n",
    "    gc.collect()\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0) if random_color else np.array([30 / 255, 144 / 255, 255 / 255, 1])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # input_folder = r\"D://code//data//howtodo_from_0401//服饰鞋靴箱包//女士休闲鞋\"\n",
    "    input_folder = \"D://code//data//Lv2期结论//女鞋_from_0501//test//6917\"\n",
    "    text = 'person,shoes'\n",
    "    process_images_in_folder(input_folder, text)\n",
    "    print('完结完结完结')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step3 - 将图片分为price/txt/white/scene四类\n",
    "这里是Lv2期的特殊需求,针对单独的cid3进行分类,读取每个cid3中的grounding_output文件夹,在其中再进行四分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from paddleocr import PaddleOCR\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 定义基础路径\n",
    "base_path = 'D://code//data//howtodo_from_0401//测试1'\n",
    "\n",
    "# 初始化 PaddleOCR\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang=\"ch\", show_log=False)\n",
    "\n",
    "def process_grounding_output(grounding_output_path):\n",
    "    price_folder = os.path.join(grounding_output_path, 'price')\n",
    "    txt_folder = os.path.join(grounding_output_path, 'txt')\n",
    "    scene_folder = os.path.join(grounding_output_path, 'scene')\n",
    "    white_folder = os.path.join(grounding_output_path, 'white')\n",
    "\n",
    "    for folder in [price_folder, txt_folder, scene_folder, white_folder]:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "    '''\n",
    "    step1 - 筛选价促卖点图\n",
    "    '''\n",
    "    print(f'Step 1: 筛选价促卖点图 - {grounding_output_path}')\n",
    "\n",
    "    image_files = [f for f in os.listdir(grounding_output_path) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "    with tqdm(total=len(image_files), desc=\"Processing images\") as pbar:\n",
    "        for filename in image_files:\n",
    "            img_path = os.path.join(grounding_output_path, filename)\n",
    "            \n",
    "            result = ocr.ocr(img_path, cls=True)\n",
    "            \n",
    "            if not result or not result[0]:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            \n",
    "            data_list = result[0]\n",
    "            \n",
    "            keywords = ['满', '减', '折', '到手价', '送', '免息', '活动价', '包邮价', '参考价', \n",
    "                        r'.*满.*减.*', r'.*满.*-.*', r'.*满.*赠.*',r'.*满.*送.*', r'.*价.*', \n",
    "                        '券', '优惠', '用券', '领券', '券', '送', '低至', '立减', '直降', '免息',\n",
    "                        '¥', '夫', '￥']\n",
    "            \n",
    "            if any(keyword in data[1][0] for data in data_list for keyword in keywords):\n",
    "                try:\n",
    "                    shutil.move(img_path, price_folder)\n",
    "                    pbar.write(f\"Image '{filename}' moved to price_folder.\")\n",
    "                except Exception as e:\n",
    "                    pbar.write(f\"Failed to move image '{filename}': {e}\")\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "    '''\n",
    "    step2 - 筛选白底图\n",
    "    '''\n",
    "    print(f'Step 2: 筛选白底图 - {grounding_output_path}')\n",
    "\n",
    "    def move_images_with_white_pixels(src_folder, dst_folder, threshold=0.40):\n",
    "        image_files = [f for f in os.listdir(src_folder) if f.endswith(('.jpg', '.png'))]\n",
    "        \n",
    "        with tqdm(total=len(image_files), desc=f\"Moving images from {src_folder}\") as pbar:\n",
    "            for filename in image_files:\n",
    "                img_path = os.path.join(src_folder, filename)\n",
    "                \n",
    "                with Image.open(img_path) as img:\n",
    "                    if img.mode != 'RGB':\n",
    "                        img = img.convert('RGB')\n",
    "                    width, height = img.size\n",
    "                \n",
    "                    white_pixels = sum(1 for x in range(width) for y in range(height) \n",
    "                                       if all(v > 230 for v in img.getpixel((x, y))[:3]))\n",
    "                    \n",
    "                    if white_pixels / (width * height) > threshold:\n",
    "                        try:\n",
    "                            shutil.move(img_path, dst_folder)\n",
    "                            pbar.write(f\"Image '{filename}' moved to white folder.\")\n",
    "                        except Exception as e:\n",
    "                            pbar.write(f\"Error moving image '{filename}': {e}\")\n",
    "                            \n",
    "                pbar.update(1)\n",
    "\n",
    "    move_images_with_white_pixels(grounding_output_path, white_folder, threshold=0.40)\n",
    "\n",
    "    '''\n",
    "    step3 - 筛选功能卖点图\n",
    "    '''\n",
    "    print(f'Step 3: 筛选功能卖点图 - {grounding_output_path}')\n",
    "\n",
    "    image_files = [f for f in os.listdir(grounding_output_path) if f.endswith(('.jpg', '.png'))]\n",
    "    for filename in image_files:\n",
    "        img_path = os.path.join(grounding_output_path, filename)\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        width, height = img.size\n",
    "        \n",
    "        cropped_img = img.crop((0, height // 6, width, height))\n",
    "        img_np = np.array(cropped_img)\n",
    "        \n",
    "        result = ocr.ocr(img_np, cls=True)\n",
    "        \n",
    "        if result and result[0] and len(result[0]) >= 2:\n",
    "            shutil.move(img_path, txt_folder)\n",
    "            print(f\"'{filename}' moved to txt folder.\")\n",
    "        else:\n",
    "            print(f\"'{filename}' remains in source folder.\")\n",
    "\n",
    "    '''\n",
    "    step4 - 将剩余图片归类到scene\n",
    "    '''\n",
    "    print(f'Step 4: 归类图片到scene - {grounding_output_path}')\n",
    "\n",
    "    image_files = [f for f in os.listdir(grounding_output_path) if f.endswith(('.jpg', '.png'))]\n",
    "    for filename in image_files:\n",
    "        img_path = os.path.join(grounding_output_path, filename)\n",
    "        shutil.move(img_path, scene_folder)\n",
    "        print(f\"Image '{filename}' moved to scene_folder.\")\n",
    "\n",
    "    '''\n",
    "    step5 - 将white中有文本的图片移到txt_folder\n",
    "    '''\n",
    "    print(f'Step 5: 将white中有文本的图片移到txt_folder - {grounding_output_path}')\n",
    "\n",
    "    image_files = [f for f in os.listdir(white_folder) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "    with tqdm(total=len(image_files), desc=\"Processing images\") as pbar:\n",
    "        for filename in image_files:\n",
    "            img_path = os.path.join(white_folder, filename)\n",
    "\n",
    "            img = Image.open(img_path)\n",
    "            width, height = img.size\n",
    "        \n",
    "            cropped_img = img.crop((0, height // 6, width, height))\n",
    "            img_np = np.array(cropped_img)\n",
    "            \n",
    "            result = ocr.ocr(img_np, cls=True)\n",
    "            \n",
    "            if result and result[0]:\n",
    "                lines_above_30_count = sum(1 for rectangle in result[0] \n",
    "                                           if min(math.sqrt((x2-x1)**2 + (y2-y1)**2) \n",
    "                                                  for (x1, y1), (x2, y2) in zip(rectangle[0], rectangle[0][1:])) > 30)\n",
    "                \n",
    "                if lines_above_30_count >= 2:\n",
    "                    shutil.move(img_path, txt_folder)\n",
    "                    pbar.write(f\"Image '{filename}' moved to txt_folder.\")\n",
    "                else:\n",
    "                    pbar.write(f\"Image '{filename}' remains in source folder.\")\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "def main():\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        if 'grounding_output' in dirs:\n",
    "            grounding_output_path = os.path.join(root, 'grounding_output')\n",
    "            print(f\"Processing: {grounding_output_path}\")\n",
    "            process_grounding_output(grounding_output_path)\n",
    "\n",
    "    print(\"All processing completed.\")\n",
    "    print(\"当前系统时间是:\", datetime.now())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
